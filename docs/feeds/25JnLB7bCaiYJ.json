{"id":"25JnLB7bCaiYJ","title":"Tech News","displayTitle":"Tech News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":85,"items":[{"title":"Shopify took down Kanye’s swastika T-shirt shop, but another antisemitic storefront still operates","url":"https://techcrunch.com/2025/02/11/shopify-took-down-kanyes-swastika-t-shirt-shop-but-another-antisemitic-storefront-still-operates/","date":1739323072,"author":"Amanda Silberling","guid":156,"unread":true,"content":"<p>Shopify took down Kanye West’s online store after the musician sold T-shirts with the swastika symbol. West, who also goes by Ye, advertised his online store in a Super Bowl commercial on Sunday, directing viewers to his website, where the only item listed was the swastika T-shirt. Though Shopify removed a policy banning sellers from […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":406,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"'Serial Swatter' Who Made Nearly 400 Threatening Calls Gets 4 Years In Prison","url":"https://yro.slashdot.org/story/25/02/11/2243253/serial-swatter-who-made-nearly-400-threatening-calls-gets-4-years-in-prison?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739322000,"author":"BeauHD","guid":297,"unread":true,"content":"Alan W. Filion, an 18-year-old from Lancaster, Calif., was sentenced to four years in prison for making nearly 400 false bomb threats and threats of violence (source may be paywalled; alternative source) to religious institutions, schools, universities and homes across the country. The New York Times reports: The threatening calls Mr. Filion made would often cause large deployments of police officers to a targeted location, the Justice Department said in a news release. In some cases, officers would enter people's homes with their weapons drawn and detain those inside. In January 2023, Mr. Filion wrote on social media that his swats had often led the police to \"drag the victim and their families out of the house cuff them and search the house for dead bodies.\"\n \nInvestigators linked Mr. Filion to over 375 swatting calls made in several states, including one that he made to the police in Sanford, Fla., saying that he would commit a mass shooting at the Masjid Al Hayy Mosque. During the call, he played audio of gunfire in the background. Mr. Filion was arrested in California in January 2024, and was then extradited to Florida to face state charges for making that threat. Mr. Filion began swatting for recreation in August 2022 before making it into a business, the Justice Department said. The teenager became a \"serial swatter\" and would make social media posts about his \"swatting-for-a-fee\" services, according to prosecutors.\n \nIn addition to pleading guilty to the false threat against the mosque in Florida, Mr. Filion pleaded guilty in three other swatting cases: a mass shooting threat to a public school in Washington State in October 2022; a bomb threat call to a historically Black college or university in Florida in May 2023; and a July 2023 call in which he claimed to be a federal law enforcement officer in Texas and told dispatchers that he had killed his mother and would kill any responding officers.","contentLength":1936,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"KDE Plasma 6.3 Released","url":"https://tech.slashdot.org/story/25/02/11/2229240/kde-plasma-63-released?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739319600,"author":"BeauHD","guid":296,"unread":true,"content":"Today, the KDE Project announced the release of KDE Plasma 6.3, featuring improved fractional scaling, enhanced Night Light color accuracy, better CPU usage monitoring, and various UI and security refinements.\n \nSome of the key features of Plasma 6.3 include: \n- Improved fractional scaling with KWin to lead to an all-around better desktop experience with fractional scaling as well as when making use of KWin's zoom effect.\n- Screen colors are more accurate with the KDE Night Light feature.\n- CPU usage monitoring within the KDE System Monitor is now more accurate and consuming fewer CPU resources.\n- KDE will now present a notification when the kernel terminated an app because the system ran out of memory.\n- Various improvements to the Discover app, including a security enhancement around sandboxed apps.\n- The drawing tablet area of KDE System Settings has been overhauled with new features and refinements.\n- Many other enhancements and fixes throughout KDE Plasma 6.3. You can read the announcement here.","contentLength":1015,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Federal workers sue Elon Musk and DOGE to cut off data access","url":"https://techcrunch.com/2025/02/11/federal-workers-sue-elon-musk-and-doge-to-cut-off-data-access/","date":1739318882,"author":"Charles Rollet","guid":155,"unread":true,"content":"<p>Federal workers are suing DOGE and its creator, Elon Musk to cut off the new agency's access to their personal data.</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":179,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tumblr To Join the Fediverse After WordPress Migration Completes","url":"https://tech.slashdot.org/story/25/02/11/2217231/tumblr-to-join-the-fediverse-after-wordpress-migration-completes?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739317200,"author":"BeauHD","guid":295,"unread":true,"content":"An anonymous reader quotes a report from TechCrunch: Since 2022, blogging site Tumblr has been teasing its plans to integrate with the fediverse -- the open social web powered by the protocol ActivityPub also used by Mastodon, Threads, Flipboard, and others. Now, the Automattic-owned blogging platform is sharing more information about when and how that integration could actually happen. As it turns out, the current plan to tie Tumblr into the open social web will come about by way of the site's planned move to the WordPress infrastructure. Automattic confirmed to TechCrunch that when the migration is complete, every Tumblr user will be able to federate their blog via ActivityPub, just as every WordPress.com user can today. The company noted that the migration could also allow for other open web integrations, like giving Tumblr users a way to run other custom plug-ins or themes.\n \nLast summer, Automattic announced it would move its half a billion blogs to WordPress, to make it easier for the company to build tools and features that worked across both services, while also allowing Tumblr to take advantage of the open source developments from WordPress.org. Though the WordPress community itself is in a state of upheaval, ultimately running Tumblr's back end on WordPress would allow for greater efficiencies, while not changing the interface and experience that Tumblr's user base has grown to love. Automattic declined to share a time frame as to when the migration would be complete, given its scale, but a rep for the company called the progress so far \"exciting.\" Automattic didn't say if it would consider integrating with the AT Protocol that powers Bluesky.","contentLength":1681,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Founders Fund is about to close another $3B fund","url":"https://techcrunch.com/2025/02/11/founders-fund-is-about-to-close-another-3b-fund/","date":1739316703,"author":"Marina Temkin","guid":154,"unread":true,"content":"<p>Founders Fund is on track to conclude fundraising of its third growth fund at the end of March, according to people close to the firm. The Peter Thiel-founded outfit is raising $3 billion, a source told TechCrunch and&nbsp;Axios also reported. The fund, which is intended primarily for additional investments in its successful late-stage portfolio companies, […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":423,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PassMark Sees the First Yearly Drop In Average CPU Performance In Its 20 Years","url":"https://hardware.slashdot.org/story/25/02/11/224223/passmark-sees-the-first-yearly-drop-in-average-cpu-performance-in-its-20-years?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739314800,"author":"BeauHD","guid":294,"unread":true,"content":"For the first time since 2004, PassMark's global CPU benchmark data shows a decline in average processor performance, with laptop CPUs dropping 3.4% and desktop CPUs falling 0.5% year-over-year. Tom's Hardware reports: We see the biggest drop in laptop CPU performance results. PassMark recorded an average result of 14,632 across 101,316 samples last year. But, in 2025, the average score sat at an average of 14,130 points between 25,541 samples, decreasing the average score by 3.4%. The average desktop PC result in 2024 netted 26,436 points for 186,053 samples. But for 2025, the average score currently sits at 26,311 points for over 47,810 samples -- a 0.5% drop from last year. While that drop is small, we should only see a continued progression of faster performance.\n \n[...] Passmark itself mused on X (formerly Twitter) that it could be that people are switching to more affordable machines that deliver lower power and performance. Or maybe Windows 11 is depressing performance scores versus Windows 10, especially as people transition to it with the upcoming demise of the latter. We've certainly seen plenty of examples of reduced performance in gaming with some of the newer versions of Windows 11, particularly as Intel and AMD struggled to upstream needed updates into the OS. [...] PassMark also muses that bloatware could contribute to the sudden decline in performance, but that seems like a longshot.","contentLength":1422,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI’s Operator vs CAPTCHAs: Who’s Winning?","url":"https://hackernoon.com/openais-operator-vs-captchas-whos-winning?source=rss","date":1739312756,"author":"Bright Data","guid":205,"unread":true,"content":"<p>: <a href=\"https://openai.com/index/introducing-operator/\">OpenAI has launched Operator</a>, an AI-powered agent that can use its own browser to perform tasks for you. Currently, it’s available only to Pro users in the U.S., but it’s coming globally soon. 🌍</p><p>\\\nCool, right? But hold up—are we sure websites won’t push back? 🤔 Will current <a href=\"https://hackernoon.com/top-5-anti-scraping-measures-you-need-to-know\">anti-bot tech</a> like IP bans, browser fingerprints, TLS fingerprints, and, of course, CAPTCHAs keep up with OpenAI’s new tool?</p><p>\\\nSo, who’s really winning in this battle between complex automated bots and anti-bot defenses? Read on to find out! 🔥</p><h2>LLM Models and Online Data: A Rocky Relationship</h2><p>When LLM models first hit the market, it was nothing short of a revolution. The way we approach everyday tasks at work changed forever, the stock market reacted with excitement 🚀, and everyone jumped on the AI train (even if there wasn’t  AI behind most online products yet).</p><p>\\\nSo, where does all that data come from? Easy answer:  🌍</p><p>\\\nThe Web is the biggest source of data on the planet, so it’s no surprise companies like <a href=\"https://help.openai.com/en/articles/7842364-how-chatgpt-and-our-foundation-models-are-developed\">OpenAI scraped the Internet for years</a> to collect the data needed to train their groundbreaking tech. And as long as web scraping is done ethically, there's nothing wrong with that 🤷.</p><p>\\\nBut here’s the catch: <strong>Most site owners aren’t thrilled about AI companies using their data!</strong> 😠</p><p>\\\nIn short, giving away your data for free is basically the same as handing out cash 💸. No wonder site owners—especially big companies—aren’t exactly thrilled about that. 😅</p><p>\\\nNow that the landscape is evolving and new AI operators and tools are entering the scene, websites may start to get  unhappy about it. 😬</p><h3>AI Operators vs Websites: The Next Phase of This Troubled Relationship</h3><blockquote><p>“Operator is powered by a new model called <a href=\"https://openai.com/index/computer-using-agent/\">Computer-Using Agent</a> (CUA). Combining GPT-4’s vision capabilities with advanced reasoning through reinforcement learning, CUA is trained to interact with graphical user interfaces (GUIs)—the buttons, menus, and text fields people see on a screen.”</p></blockquote><p>\\\nIt’s clear that, while AI companies like OpenAI have previously built scraping bots to gather data from popular sources to train their models, they’re now giving users a tool that can “magically” interact with and navigate websites. That’s both exciting and scary! 😱</p><p>\\\nSee OpenAI's Operator in action in the presentation video:</p><p>\\\nAgain, from the official presentation article:</p><blockquote><p>“Operator can “see” (through screenshots) and “interact” (using all the actions a mouse and keyboard allow) with a browser, enabling it to take action on the web without requiring custom API integrations.</p><p>\\\n  If it encounters challenges or makes mistakes, Operator can leverage its reasoning capabilities to self-correct. When it gets stuck and needs assistance, it simply hands control back to the user, ensuring a smooth and collaborative experience.”</p></blockquote><p>\\\nThat’s incredibly promising, but it also raises some serious concerns. 🤔 What if users start abusing Operator for malicious purposes? We’ve all had enough of bots (like those spammy comments flooding YouTube), and this could quickly spiral into a major problem. ⚠️</p><p>\\\nAssuming OpenAI manages to prevent Operator from performing harmful or unwanted actions—just like they've worked to keep ChatGPT from answering dangerous questions—can we really be sure that most websites will welcome this kind of new, automated, AI-powered interaction? 🤖</p><p>Before diving into the big question we left open, let’s first clarify what kind of interactions we’re dealing with. At the end of the day, if these new AI operators aren’t as effective as we think, why should we even bother protecting against them in the first place? 👀</p><p>\\\nCurrently, <strong>only U.S. users paying $200 a month for the highest subscription tier of ChatGPT Pro can access OpenAI’s Operator</strong>, so not everyone has had the chance to test it out. But for those who have? The results are impressive! 🤯</p><p>\\\nEarly users and <a href=\"https://www.nytimes.com/2025/02/01/technology/openai-operator-agent.html\">tech reviewers</a> found OpenAI’s amazing at automating everyday tasks like:</p><ul><li>Ordering food (yes, it can even automatically make decisions like choosing what restaurants to order from 🍔)</li><li>Replying to users on some social media platforms</li><li>Completing small online tasks such as filling out surveys for rewards</li></ul><p>\\\nHow is that possible? Operator opens a mini browser window and completes tasks based on your text prompts—just like a regular user would:</p><p>\\\nSure, the product is still in the “research preview” stage and isn’t perfect. Occasionally, you’ll need to give it a nudge or rescue it from a loop of failed attempts.</p><p>\\\n➡️ The real question now: Will websites welcome AI-powered automation, or will they fight back? And if they do, how? ⚔️</p><h2>How Websites Are Fighting Back Against AI</h2><p><a href=\"https://hackernoon.com/how-to-scrape-modern-spas-pwas-and-ai-driven-dynamic-sites\">Anti-bot and anti-scraping solutions</a> are nothing new—many sites have been using them for years to protect against automated scripts scraping data and interacting with their pages. 🚫</p><p>\\\nIf you’re curious about these methods, check out our webinar on advanced anti-bot techniques:</p><ul><li><p>: Tools that restrict the number of requests from a user in a given time to prevent overload. They work by <a href=\"https://hackernoon.com/how-to-avoid-an-ip-ban-with-proxies\">banning IPs</a>.</p></li><li><p>: A method that tracks the unique characteristics of a browser’s encrypted connection to identify bots. Explore the role of <a href=\"https://hackernoon.com/the-role-of-the-tls-fingerprint-in-web-scraping\">TLS fingerprinting in web scraping</a>.</p></li><li><p>: A technique for detecting unique device or browser attributes to spot automated tools.</p></li></ul><p>These initial defenses focus on blocking requests from automated tools (like AI operators) before they even get a chance to access the site 🛡️.</p><p>\\\nIf those defenses fail, other techniques come into play. Some examples? </p><p>CAPTCHAs are particularly effective because they’re designed to be easy for humans to solve, but tough for bots to crack.</p><p>\\\nBut with AI getting smarter and starting to think more like humans, recognizing bots is becoming harder. This is why some wild ideas, like <a href=\"https://hackernoon.com/doom-captcha-are-video-games-the-future-of-captcha\">using video games as CAPTCHAs</a>, are being tossed around. 🎮</p><p>\\\nBut the real question is—are CAPTCHAs the ultimate solution against AI operators? Let’s dive in and find out! 💡</p><h2>Solving CAPTCHAs: Can AI Operators Really Beat the System?</h2><p>: Nope, not really… 🙅‍♂️</p><p>\\\nSince OpenAI Operator hit the market for testing, users have been pushing it to complete tasks that involve CAPTCHAs—logging into social media, filling out forms, and more.</p><blockquote><p>“While it handles most steps automatically, CUA seeks user confirmation for sensitive actions, such as entering login details or responding to CAPTCHA forms.”</p></blockquote><p>\\\nSure, sometimes the AI’s reasoning engine might sneak past a CAPTCHA 🥷, but more often than not, —with results that are both hilarious and frustrating. When put to the test on <strong>Reddit, Google Maps, Amazon, and G2</strong>, it repeatedly gets shut down by anti-bot protections.</p><p>Watching AI operators crash and burn against CAPTCHAs has become a viral trend. Videos of these AI tools fumbling their way through login attempts are flooding Reddit and X:</p><p>\\\nOn one hand, this is reassuring—CAPTCHAs are doing their job and stopping automated bots from wreaking havoc. On the other hand, <strong>we’re in a cat-and-mouse game</strong> 🐁 🐈. Anti-bot tech and AI operators will keep evolving, taking turns being one step ahead.</p><p>\\\nThe real losers? Regular users! More sites will likely implement CAPTCHAs, making browsing more painful for everyone. And let’s be honest—we all hate CAPTCHAs. 😩</p><p>\\\nThis battle doesn’t just affect AI operators—ethical web scrapers are also getting caught in the crossfire. As sites ramp up anti-bot measures, legitimate scraping scripts will be unfairly blocked, <strong>making data extraction harder for researchers, businesses, and developers</strong>.</p><p>\\\nLuckily, there’s a better way to interact with sites programmatically  dealing with CAPTCHAs and other anti-bot nightmares: <a href=\"https://brightdata.com/products/scraping-browser?utm_source=brand&amp;utm_campaign=brnd-mkt_content_hackernoon\">Scraping Browser</a>!</p><h2>The Real Winner? Bright Data’s Scraping Browser!</h2><p>OpenAI Operator automates regular browsers just like other browser automation tools. But here’s the thing—most anti-bot technologies, including CAPTCHAs, don’t appear  of the automation itself. They show up <strong>due to how the browser is configured</strong>!</p><p>\\\nMost browser automation libraries set up browsers in ways that expose them as automated, completely defeating the purpose of using a “regular” browser. That’s where anti-bot systems step in and block access. 🚫</p><p>\\\nInstead of focusing on whether AI can bypass CAPTCHAs, the real game-changer is using the right browser—one <strong>optimized for scraping and automation</strong>. That’s exactly where <a href=\"https://brightdata.com/products/scraping-browser?utm_source=brand&amp;utm_campaign=brnd-mkt_content_hackernoon\">Bright Data’s Scraping Browser</a> comes in, packed with:</p><ul><li><p><strong>Reliable TLS fingerprints</strong> to avoid detection</p></li><li><p> for large-scale data extraction</p></li><li><p> powered by a 72-million IP proxy network</p></li><li><p> to handle failed requests</p></li><li><p><strong>CAPTCHA-solving superpowers</strong> that outperform AI operators 🧠</p></li></ul><p>\\\nBright Data’s CAPTCHA solver has proven successful against:</p><ul><li>reCAPTCHA ✔️ (yep, the one OpenAI Operator couldn’t solve in the tweet above)</li></ul><p>\\\nNot only does it <strong>reduce the chances of CAPTCHAs appearing</strong>, but when they do show up, it . 🔥</p><p>\\\nScraping Browser works with all major browser automation frameworks—including Playwright, Puppeteer, and Selenium. So whether you want full programmatic control or <strong>even to add AI logic on top</strong>, you’re covered.</p><p>\\\nSee Bright Data’s Scraping Browser in action:</p><p>\\\nSo… should we keep forcing AI to solve CAPTCHAs, or just use a tool that works? The choice is obvious.  🏆</p><p>OpenAI’s Operator is here to revolutionize web interaction—but it’s not all-powerful. While impressive, it still struggles against CAPTCHAs and gets blocked.</p><p>\\\nAvoid the hassle with Scraping Browser, featuring a built-in CAPTCHA Solver for seamless automation. Embark on our quest to democratize the Web, ensuring it remains accessible for all, everywhere, even through automated scripts!</p><p>\\\nUntil next time, keep exploring the Internet freely and without CAPTCHAs!</p>","contentLength":9821,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AUKUS Blasts Holes In LockBit's Bulletproof Hosting Provider","url":"https://it.slashdot.org/story/25/02/11/2156211/aukus-blasts-holes-in-lockbits-bulletproof-hosting-provider?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739312400,"author":"BeauHD","guid":293,"unread":true,"content":"The US, UK, and Australia (AUKUS) have sanctioned Russian bulletproof hosting provider Zservers, accusing it of supporting LockBit ransomware operations by providing secure infrastructure for cybercriminals. The sanctions target Zservers, its UK front company XHOST Internet Solutions, and six individuals linked to its operations. The Register reports: Headquartered in Barnaul, Russia, Zservers provided BPH services to a number of LockBit affiliates, the three nations said today. On numerous occasions, affiliates purchased servers from the company to support ransomware attacks. The trio said the link between Zservers and LockBit was established as early as 2022, when Canadian law enforcement searched a known LockBit affiliate and found evidence they had purchased infrastructure tooling almost certainly used to host chatrooms with ransomware victims.\n \n\"Ransomware actors and other cybercriminals rely on third-party network service providers like Zservers to enable their attacks on US and international critical infrastructure,\" said Bradley T Smith, acting under secretary of the Treasury for terrorism and financial intelligence. \"Today's trilateral action with Australia and the United Kingdom underscores our collective resolve to disrupt all aspects of this criminal ecosystem, wherever located, to protect our national security.\" The UK's Foreign, Commonwealth &amp; Development Office (FCDO) said additionally that the UK front company for Zservers, XHOST Internet Solutions, was also included in its sanctions list. According to Companies House, the UK arm was incorporated on January 31, 2022, although the original service was established in 2011 and operated in both Russia and the Netherlands. Anyone found to have business dealings with either entity can face criminal and civil charges under the Sanctions and Anti-Money Laundering Act 2018.\n \nThe UK led the way with sanctions, placing six individuals and the two entities on its list, while the US only placed two of the individuals -- both alleged Zservers admins -- on its equivalent. Alexander Igorevich Mishin and Aleksandr Sergeyevich Bolshakov, both 30 years old, were named by the US as the operation's heads. Mishin was said to have marketed Zservers to LockBit and other ransomware groups, managing the associated cryptocurrency transactions. Both he and Bolshakov responded to a complaint from a Lebanese company in 2023 and shut down an IP address used in a LockBit attack. The US said, however, it was possible that the pair set up a replacement IP address that LockBit could carry on using, while telling the Lebanese company that they complied with its request. The UK further sanctioned Ilya Vladimirovich Sidorov, Dmitry Konstantinovich Bolshakov (no mention of whether he is any relation to Aleksandr), Igor Vladimirovich Odintsov, and Vladimir Vladimirovich Ananev. Other than that they were Zservers employees and thus were directly or indirectly involved in attempting to inflict economic loss to the country, not much was said about either of their roles.","contentLength":3050,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"New hack uses prompt injection to corrupt Gemini’s long-term memory","url":"https://arstechnica.com/security/2025/02/new-hack-uses-prompt-injection-to-corrupt-geminis-long-term-memory/","date":1739312022,"author":"Dan Goodin","guid":359,"unread":true,"content":"<p>In the nascent field of AI hacking, indirect prompt injection has become a basic building block for inducing chatbots to exfiltrate sensitive data or perform other malicious actions. Developers of platforms such as Google's Gemini and OpenAI's ChatGPT are generally good at plugging these security holes, but hackers keep finding new ways to poke through them again and again.</p><p>On Monday, researcher Johann Rehberger demonstrated a new way to override prompt injection defenses Google developers have built into Gemini—specifically, defenses that restrict the invocation of Google Workspace or other sensitive tools when processing untrusted data, such as incoming emails or shared documents. The result of Rehberger’s attack is the permanent planting of long-term memories that will be present in all future sessions, opening the potential for the chatbot to act on false information or instructions in perpetuity.</p><p>More about the attack later. For now, here is a brief review of indirect prompt injections: Prompts in the context of large language models (LLMs) are instructions, provided either by the chatbot developers or by the person using the chatbot, to perform tasks, such as summarizing an email or drafting a reply. But what if this content contains a malicious instruction? It turns out that chatbots are so eager to follow instructions that they often take their orders from such content, even though there was never an intention for it to act as a prompt.</p>","contentLength":1470,"flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2023/12/gemini_header-1152x648.jpg","enclosureMime":"","commentsUrl":null},{"title":"Apple Maps plans to show ‘Gulf of America,’ following Google","url":"https://techcrunch.com/2025/02/11/apple-maps-plans-to-show-gulf-of-america-following-google/","date":1739311774,"author":"Maxwell Zeff","guid":153,"unread":true,"content":"<p>Apple Maps will soon rename the Gulf of Mexico to the Gulf of America, following similar changes made by Google this week, in order to comply with U.S. President Donald Trump’s executive order that officially changed the name. U.S.-based Apple users may see the “Gulf of America” as soon as Tuesday, according to Bloomberg, and […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ChatGPT may not be as power-hungry as once assumed","url":"https://techcrunch.com/2025/02/11/chatgpt-may-not-be-as-power-hungry-as-once-assumed/","date":1739311226,"author":"Kyle Wiggers","guid":152,"unread":true,"content":"<p>ChatGPT, OpenAI’s chatbot platform, may not be as power-hungry as once assumed. But its appetite largely depends on how ChatGPT is being used and the AI models that are answering the queries, according to a new study. A recent analysis by Epoch AI, a nonprofit AI research institute, attempted to calculate how much energy a […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":395,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python 3.14 Alpha 5 Released With New Tail-Call Interpreter","url":"https://www.phoronix.com/news/Python-3.14-Alpha-5","date":1739310817,"author":"Michael Larabel","guid":715,"unread":true,"content":"<article>Python 3.14 Alpha 5 is out today as the latest of many development releases in stepping toward the Python 3.14 stable release in October...</article>","contentLength":139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amazon tests sending customers directly to brands’ websites when it doesn’t stock their products","url":"https://techcrunch.com/2025/02/11/amazon-tests-sending-customers-directly-to-brands-websites-when-it-doesnt-stock-their-products/","date":1739310765,"author":"Sarah Perez","guid":151,"unread":true,"content":"<p>Remember that Christmas movie “Miracle on 34th Street,” where Macy’s in-store Santa, Kris Kringle, sends a frazzled shopper to a competitor’s store to find the Christmas present her son wanted because Macy’s was out of stock? Now Amazon is doing the same thing online. The retailer announced on Tuesday the test of a new Amazon […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":406,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Thomson Reuters Wins First Major AI Copyright Case In the US","url":"https://yro.slashdot.org/story/25/02/11/2139217/thomson-reuters-wins-first-major-ai-copyright-case-in-the-us?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739310000,"author":"BeauHD","guid":292,"unread":true,"content":"An anonymous reader quotes a report from Wired: Thomson Reuters has won the first major AI copyright case in the United States. In 2020, the media and technology conglomerate filed an unprecedentedAI copyright lawsuit against the legal AI startup Ross Intelligence. In the complaint, Thomson Reuters claimed the AI firm reproduced materials from its legal research firm Westlaw. Today, a judge ruled (PDF) in Thomson Reuters' favor, finding that the company's copyright was indeed infringed by Ross Intelligence's actions. \"None of Ross's possible defenses holds water. I reject them all,\" wrote US District Court of Delaware judge Stephanos Bibas, in a summary judgement. [...] Notably, Judge Bibas ruled in Thomson Reuters' favor on the question of fair use.\n \nThe fair use doctrine is a key component of how AI companies are seeking to defend themselves against claims that they used copyrighted materials illegally. The idea underpinning fair use is that sometimes it's legally permissible to use copyrighted works without permission -- for example, to create parody works, or in noncommercial research or news production. When determining whether fair use applies, courts use a four-factor test, looking at the reason behind the work, the nature of the work (whether it's poetry, nonfiction, private letters, et cetera), the amount of copyrighted work used, and how the use impacts the market value of the original. Thomson Reuters prevailed on two of the four factors, but Bibas described the fourth as the most important, and ruled that Ross \"meant to compete with Westlaw by developing a market substitute.\" \"If this decision is followed elsewhere, it's really bad for the generative AI companies,\" says James Grimmelmann, Cornell University professor of digital and internet law. \nChris Mammen, a partner at Womble Bond Dickinson who focuses on intellectual property law, adds: \"It puts a finger on the scale towards holding that fair use doesn't apply.\"","contentLength":1963,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to delete Facebook, Instagram, and Threads","url":"https://techcrunch.com/2025/02/11/how-to-delete-facebook-instagram-and-threads/","date":1739309773,"author":"Rebecca Bellan","guid":150,"unread":true,"content":"<p>In the wake of Meta’s decision to remove its third-party fact-checking system and loosen content moderation policies, Google searches on how to delete Facebook, Instagram, and Threads have been on the rise. People who are angry with the decision accuse Meta CEO Mark Zuckerberg of cozying up to the Trump administration at the expense of […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":408,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google’s I/O developer conference set for May 20-21","url":"https://techcrunch.com/2025/02/11/googles-i-o-developer-conference-set-for-may-20-21/","date":1739309079,"author":"Brian Heater","guid":149,"unread":true,"content":"<p>Google Tuesday confirmed that its annual developer conference is set for May 20-21, 2025. The event will be held at the usual spot, Mountain View’s Shoreline Amphitheater, a few minutes — depending on traffic — from Google HQ. The two-day event is a mix of both public- and developer-facing content. CEO Sundar Pichai will kick […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Top Blazor UI Components: Everything You Need to Know","url":"https://hackernoon.com/the-top-blazor-ui-components-everything-you-need-to-know?source=rss","date":1739308771,"author":"MESCIUS inc.","guid":204,"unread":true,"content":"<p>Any Blazor application developed today requires complex functionality. This can include many features, from efficiently handling responsive design to top-notch data visualization. The Blazor framework is popular among .NET developers because they can use HTML, CSS, and C# in lieu of JavaScript to create the highest quality web UI experiences. However, to develop the ultimate application, you need a .NET UI toolkit to put all the modern web controls at your disposal—a first-rate Blazor UI component library.</p><p>Any worthwhile Blazor UI components should include most or all the following features:</p><ul><li><strong>Chart types and data visualization options:</strong>&nbsp;Data visualization is part of the foundation of modern business or analytical applications.</li><li><strong>Ability to build custom dashboards:</strong>&nbsp;Businesses use custom dashboards to gain insights into their performance and make informed business decisions.</li><li><strong>Wide range of input and editing features:</strong>&nbsp;Text fields that can be edited facilitate the collection of user data and encourage users to engage with digital content.</li><li><strong>Controls that support Blazor Server and Web Assembly:</strong>&nbsp;These controls can be used for both server-side and client-side applications.</li><li>&nbsp;How easy is managing dependencies or distributing reusable code?</li><li><strong>Use C# code on both the server and client side:</strong>&nbsp;The reusability of C# is necessary for improving software development efficiency.</li><li><strong>Reporting and documentation capabilities:</strong>&nbsp;What reporting tools does the library have, and can they efficiently handle large datasets?</li><li><strong>Customizable navigation and layout options:</strong>&nbsp;There should be enough components to customize the applications’ views easily.</li><li><strong>Native Blazor components:</strong>&nbsp;Does the library use only wrapped JavaScript components? Reusing workable code is always good, but wrapped JavaScript components can make your development unnecessarily complex, hamstring performance, and take time to build.</li><li><strong>Similar component availability in other .NET platforms:</strong>&nbsp;Can you build hybrid Blazor apps?</li></ul><p>\\\nWe researched and created a shortlist of the top Blazor UI component libraries. Read on to see how they stack up against one another and to determine which would be your preferred choice.</p><p><a href=\"https://developer.mescius.com/componentone/blazor-ui-controls\">ComponentOne</a>&nbsp;offers a solid roster of native Blazor components that can be run on both the server and client sides. You can purchase only the Blazor library or invest in the premium option, ComponentOne Studio Enterprise, which includes every .NET platform.</p><h3>Key Features and Capabilities</h3><ul><li>FlexGrid, a Blazor&nbsp;<a href=\"https://developer.mescius.com/componentone/blazor-ui-controls/flexgrid-datagrid-blazor\">datagrid</a>&nbsp;control that can edit, sort, filter, and group tabular data. It includes a&nbsp;transposed view&nbsp;extension, which supports a grid where the rows and columns are transposed.</li><li>You can use&nbsp;data filters&nbsp;that are auto-generated from a data source or manually created to supply multiple data filters to users at runtime.</li><li>On-demand data virtualization capability enables large data to load automatically while the user scrolls in real-time.</li><li>More than 50&nbsp;<a href=\"https://developer.mescius.com/componentone/blazor-ui-controls/flexchart-blazor-chart-controls\">chart</a>&nbsp;types, including Cartesian, pie, and specialty chart types, you can use to create custom dashboards.</li><li>The&nbsp;<a href=\"https://developer.mescius.com/componentone/flexreport-net-reporting-engine\">FlexReport</a>&nbsp;component can generate data-bound reports completely in C# code on the server or client.</li><li>FlexViewer enables the viewing and printing of reports and PDF documents.</li><li>Numerous input editors enable functions such as autocomplete, date and time selection, pagination, and more.</li><li>Comprehensive document processing for PDF and Excel formats.</li><li>Easy package management with ComponentOne NuGet packages.</li><li>You can integrate ComponentOne controls into other .NET platforms.</li><li>Navigation and layout options, such as accordion, treeview, tooltip, and window, let you customize views to suit your application’s needs.</li></ul><ul><li>Some premium features, such as data connectors that can integrate data from multiple data sources, are available only with the more comprehensive, higher-cost licensing option.</li></ul><p>The ComponentOne Blazor UI library has powerful UI controls that can be easily customized and extended to cater to specific application requirements for an affordable, low price compared to other offerings. You can quickly create complex views, enable data visualization for any use case, use document processing, and many other functionalities to create the ultimate user experience. There is plenty of documentation and extensive support to help you get the most out of this library.</p><p><a href=\"https://www.infragistics.com/products/ignite-ui-blazor?utm_source=bing&amp;utm_medium=CPC&amp;utm_campaign=Ignite-UI-Blazor&amp;utm_term=US-Search-Dev-ETA2\">Infragistics Ignite UI</a>&nbsp;offers a feature-rich library of more than 60 native Blazor controls developers can use to enable the frictionless design and development of web applications. Its most&nbsp;recent update improves charting features with more low-code capabilities.</p><h3>Key Features and Capabilities</h3><ul><li>A Dock Manager component uses panes to facilitate the layout arrangement of an application.</li><li>The map component displays geographic location data from view models or geospatial data obtained from the shape files on geographic imagery maps.</li><li>Data Grid is a component used to display tabular data in a series of rows and columns.</li><li>The grid component's state persistence feature improves user experience by allowing you to save user preferences or restore session data after the page reloads.</li><li>An extensive chart selection with over 65 charts and graphs can help achieve any application use case. All the chart features, such as animations, annotations, and the data legend, are customizable.</li><li>An automatic data visualization component analyzes a data source or data point to determine the most appropriate visualization to display.</li></ul><ul><li>With a starting price plan of $1,095 per developer, it is slightly more expensive than other UI component libraries.</li><li>Using the components efficiently requires a learning curve, as they appear to be wrapped versions of their JavaScript controls.</li><li>The documentation and samples could be expanded to include more specialized use cases.</li></ul><p>Infragistics’ selection of controls and built-in functionality can help developers create better application experiences faster while ensuring the application's requirements are met. A wide range of charts with key customization options can provide high-quality data visualizations. While the library’s documentation could improve, it does seem to include a robust user support framework for tailored assistance.</p><h2>Telerik Blazor UI Library</h2><p>Telerik adheres to the “more is more” philosophy and focuses on improving its existing components while creating new ones. Its&nbsp;<a href=\"https://www.telerik.com/blazor-ui\">Blazor UI library</a>&nbsp;currently includes more than 110 components—all native, customizable Blazor components rather than wrappers over jQuery widgets.</p><h3>Key Features and Capabilities</h3><ul><li>It makes customization easy with a Figma plug-in that eliminates the need for complex CSS.</li><li>Page templates are available for dashboards, landing pages, and e-commerce or product listing sites.</li><li>Components are specially designed to work with large volumes of data.</li><li>With more than 100 features, the Data grid component allows you to filter, sort, group, and export data in a grid.</li><li>Document processing for PDF, Word (DOCX, RTF, HTML, and TXT), Excel, and ZIP archives.</li><li>Gauge components let you visualize data values against a scale to identify them as suitable or sub-par values quickly.</li><li>Cross-platform capabilities allow you to embed Telerik UI for Blazor web components in .NET MAUI, WPF, or WinForms applications.</li></ul><ul><li>You may find it lacking in highly developed and designed environments where the app is customer-facing.</li><li>Learning how to implement the components can be difficult for specific use cases not addressed throughout the demo examples.</li><li>According to customer reviews, updating may break existing components.</li></ul><p>Telerik is an easy choice if you are looking for a library that provides more than just basic features. The library has a deep collection of tools with advanced features that can help you streamline and simplify the development process, saving valuable time while you create superior applications.</p><p><a href=\"https://blazorise.com/\">Blazorise</a>&nbsp;provides development independent of CSS frameworks, exclusively using C#. It supports multiple CSS frameworks, such as Tailwind, AntDesign, and Fluent 2. There are over 80 components, all of which include support for both Blazor Server and Blazor WebAssembly, making it a versatile choice for building Blazor applications across different deployment scenarios. Depending on application needs, you can use the free Community Blazorise core or one of the three paid plans. In the Enterprise and Enterprise Plus plans, you’ll enjoy access to&nbsp;premium themes&nbsp;and&nbsp;Blazorise blocks.</p><h3>Key Features and Capabilities</h3><ul><li>Templates based on the&nbsp;<a href=\"https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-new-sdk-templates\">dotnet template</a>&nbsp;give you a head start on your Blazor project.</li><li>A data grid component includes many features, such as fast data processing, pagination, sorting, and more.</li><li>Leverage a validation system for multiple use cases. Functionalities include validation handling and data annotation, as well as automated and manual validations.</li><li>A wide selection of chart types with many features, such as multiple axes, data binding, legends, zooming, animation, annotations, and tooltips.</li><li>A video component supports DRM-protected videos and almost any type of media that has DASH or HLS-encoded video.</li><li>Reporting and documentation capabilities include a PDF viewer. You can also add a rich text editor.</li><li>Navigation and layout components, such as breadcrumbs and sidebars, are specifically designed to be highly flexible.&nbsp;&nbsp;</li></ul><ul><li>There is no functionality to&nbsp;export data to an Excel file.</li><li>Some advanced components can have limitations.</li></ul><p>C# developers will find Blazorise simple to use to create custom components. There are plenty of built-in features for any UI requirements. However, some developers may consider the inability to export data to Excel files very inconvenient.</p><p><a href=\"https://www.syncfusion.com/blazor-components\">Syncfusion’s</a>&nbsp;native Blazor component library features over 90 components for Blazor server-side and client-side projects. Under its&nbsp;community license, you can use the entire product line free of charge as long as you meet certain qualifications.</p><h3>Key Features and Capabilities</h3><ul><li>The DataGrid component provides numerous functionalities, including editing, data binding, custom sorting, selection, and aggregating rows.</li><li>The chart component has more than 50 charts and graphs with high-performance points, which allows for quick processing of large data amounts. There are also plenty of customization options, such as tooltips and highlighting.</li><li>Create custom and interactive dashboards using the layout component.</li><li>Document processing capabilities let you add Excel, PDF, Word, and PowerPoint viewing and editing capabilities to your applications. A WYSIWYG editor provides editing capabilities similar to those of Microsoft Word.</li><li>Event calendars enable synchronization with Outlook and Google calendars and provide responsive layout, localization, built-in view modes, and more.</li><li>Online documentation is comprehensive.</li></ul><ul><li>Some of the components can require more time and effort to customize.</li><li>Components appear to be wrapped versions of their JavaScript controls, which may require you to learn more JavaScript to configure them.</li><li>Managing licenses is not always a seamless process; a new license key is needed every time you update Syncfusion in an application.</li><li>The online documentation is rather extensive but can be lacking.</li></ul><p>Syncfusion provides a valuable toolbox for designing and developing modern .NET applications in Blazor. Its data visualization tools make it easy to present large and complex datasets.</p><p>\\\nWhile the online documentation may be insufficient, especially for specialized queries, you will likely find what you need in blogs, forums, knowledge base, and support.</p><p>With more than 70 native Blazor components, the&nbsp;<a href=\"https://www.devexpress.com/blazor/\">DevExpress Blazor UI library</a>&nbsp;can help you speed up the development process. Its most&nbsp;recent release&nbsp;included several Blazor enhancements, including the integration of AI.</p><h3>Key Features and Capabilities</h3><ul><li>A Data Grid component can easily handle large datasets and bind to remote data.</li><li>You can use&nbsp;<a href=\"https://www.devexpress.com/blazor/data-editors/\">data editors</a>&nbsp;alone or edit cell values to group items, making lists more readable.</li><li>Document processing includes exporting to PDF, XLS, XLSX, RTF, DOCX, MHT, HTML, TXT, CSV, and image formats.</li><li>Cross-platform capabilities enable the development of&nbsp;Blazor Hybrid hosting models.</li><li>AI-supported chat, HTML, and RTF editor extensions are available.</li><li>Online documentation and tutorials are comprehensive.</li></ul><ul><li>With just over 20 types of charts, data visualization options may be more limited compared with other libraries.</li><li>Certain functionalities are not inherent in the controls; in some cases, you may have to add some functions manually.</li></ul><p>While the number of components may be less than some other libraries on this list, DevExpress still has a full suite of flexible Blazor UI components that can simplify the development process. The Data Grid component, in particular, can save development time. It includes all the typical functionalities for a modern web application, even if the options, such as chart selection, may not be as expansive as others.</p><p><a href=\"https://blazor.radzen.com/?theme=material3\">Radzen Blazor</a>&nbsp;components are a free, open-source option for .NET developers. There are more than 90 native Blazor components. Radzen also provides paid plans, including one that provides a low-code option and another that provides access to premium features.</p><h3>Key Features and Capabilities</h3><ul><li>The Radzen Blazor for Visual Studio extension integrates components directly into the familiar Visual Studio 2022 to connect to data, design, seamlessly code, and work faster.</li><li>Data visualization capabilities include charts, gauges, GoogleMaps, sparkline, timeline, and an SSRS viewer (which displays a report created in SQL Server Reporting Services).</li><li>Customize navigation with options like accordion, carousel, context menu, links, and more.</li><li>Shape the UI by specifying themes, colors, borders, and other attributes.</li><li>The Pro plan includes UI blocks, cards, calls-to-actions, features, footers, and page headings.</li><li>You can customize forms using the autocomplete, listbox, button, and color picker components, among others.&nbsp;</li></ul><ul><li>Limited reporting and documentation capabilities (SSRS).</li><li>A limited number of chart types and data visualizations compared to the paid-for offerings.</li><li>Most of the examples provided seem to focus on the free components.</li><li>The current templates provide basic, useful features but require extensive customization to make them useful for applications.</li></ul><p>Radzen’s Blazor component library is a relatively young product compared to the other libraries on this list. Its inadequate documentation is a weakness. The sample offering could also be improved by including examples in the paid plans. Still, it is a powerful tool that will help developers save time.</p><p>There are many similarities among the libraries included in this list. For example, they all support .NET 9.0. However, when you consider that you must constantly weigh a project’s requirements against the effectiveness of the Blazor component library, ComponentOne from MESCIUS stands out as the top choice.</p><p>\\\nComponentOne has extensive components that provide the ultimate developer experience for a reasonable, low price. Ease-of-use and customization are both focus points of the library. It makes efficient use of code by enabling migration to other platforms. Components like the <a href=\"https://developer.mescius.com/componentone/blazor-ui-controls/flexgrid-datagrid-blazor\">FlexGrid</a> control can easily and quickly handle massive datasets. There is a wide selection of highly customizable charts for data visualizations to create tailored dashboards that suit the application's needs. Additional capabilities, like reporting, documentation, input editors, and much more, ensure you can create high-quality web applications.</p>","contentLength":15414,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microsoft powers AI ambitions with 400 MW solar purchase","url":"https://techcrunch.com/2025/02/11/microsoft-powers-ai-ambitions-with-400-mw-solar-purchase/","date":1739308314,"author":"Tim De Chant","guid":148,"unread":true,"content":"<p>Microsoft has added another 389 megawatts of renewable power to its portfolio as the tech giant scrambles to meet the power demands required to match its AI ambitions.&nbsp; The additional renewable power spans three solar projects developed by EDP Renewables North America — two in southern Illinois and one outside Austin, Texas. Microsoft is buying […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":418,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Anduril To Take Over Managing Microsoft Goggles for US Army","url":"https://tech.slashdot.org/story/25/02/11/2011222/anduril-to-take-over-managing-microsoft-goggles-for-us-army?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739307300,"author":"msmash","guid":291,"unread":true,"content":"Anduril will take over management and eventual manufacturing of the U.S. Army's Integrated Visual Augmentation System (IVAS) from Microsoft, a significant shift in one of the military's most ambitious augmented reality projects. \n\nThe deal, which requires Army approval, could be worth over $20 billion in the next decade if all options are exercised, according to Bloomberg. The IVAS system, based on Microsoft's HoloLens mixed reality platform, aims to equip soldiers with advanced capabilities including night vision and airborne threat detection. \n\nUnder the new arrangement, Microsoft will transition to providing cloud computing and AI infrastructure, while Anduril assumes control of hardware production and software development. The Army has planned orders for up to 121,000 units, though full production hinges on passing combat testing this year. \n\nThe program has faced technical hurdles, with early prototypes causing headaches and nausea among soldiers. The current slimmer version has received better feedback, though cost remains a concern - the Army indicated the $80,000 per-unit price needs to \"be substantially less\" to justify large-scale procurement. \n\nAnduril founder Palmer Luckey, writing in a blog post: This move has been so many years in the making, over a decade of hacking and scheming and dreaming and building with exactly this specific outcome clearly visualized in my mind's eye. I can hardly believe I managed to pull it off. Everything I've done in my career -- building Oculus out of a camper trailer, shipping VR to millions of consumers, getting run out of Silicon Valley by backstabbing snakes, betting that Anduril could tear people out of the bigtech megacorp matrix and put them to work on our nation's most important problems -- has led to this moment. IVAS isn't just another product, it is a once-in-a-generation opportunity to redefine how technology supports those who serve. We have a shot to prove that this long-standing dream is no windmill, that this can expand far beyond one company or one headset and act as a a nexus for the best of the best to set a new standard for how a large collection of companies can work together to solve our nation's most important problems.","contentLength":2224,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neverending Options: Trading Options To Infinity And Beyond","url":"https://hackernoon.com/neverending-options-trading-options-to-infinity-and-beyond?source=rss","date":1739305829,"author":"2077 Research","guid":203,"unread":true,"content":"<p>Explore the evolution of crypto options and perpetual futures, including innovations like panoptions, and the challenges of liquidity and decentralization.</p><p>\\\nCrypto was born to disrupt the financial world, and it has, albeit not in the way Satoshi Nakamoto intended. In becoming so much more, it grew into a massive playground for speculation. Traders weren’t satisfied with spot trading and turned their eyes to derivatives like futures and options.</p><p>\\\nIn this article, we break down options—how they differ from futures and the evolution of perpetual options on centralised and decentralised exchanges. We also examine flaws and challenges and speculate on what the future holds. Sit tight, and let’s dive in!</p><p>A futures contract is an agreement between two parties to buy/sell a certain asset (the underlying) at a given time in the future. At first, futures were invented to hedge risks associated with commodities like soy, crude oil, or gold. A seller can set a price before they can deliver the underlying and let the buyer assume some of the risks. Since you don't get the underlying when you sign the contract, you don't have to pay the full price. Instead, a deposit equal to a portion of your position's value is all you need to keep this contract valid. Therefore, you can sign a futures contract worth $100 with only $10 and if the price goes up by 10% to $110, you will get a 100% profit ($10). Such is the power of leverage and is ideal for crypto investors seeking to amplify their returns.</p><p>\\\nEventually, someone realized you don't have to deliver the product at a given time because cryptocurrencies will always be there. A futures contract that never expires looks tempting to anyone seeking 100X their investments.</p><p>\\\nThere is one caveat, though. Since Satoshi Nakamoto released his famous whitepaper, the overwhelming majority of the crypto community has been longing cryptocurrencies. As a consequence, the futures market will be dominated by buyers, moving the futures price ridiculously higher than its spot price.</p><p>\\\nTraditional futures contracts also have this problem but the market has a way to manage it. These contracts expire, so any deviation between the futures price and the spot price gradually disappears as the expiry date approaches.It happens because the difference between buying on the futures market and the spot market becomes smaller over time.</p><p>\\\nThe same can not be said for perpetual futures. Now that they don't expire, we may never see the day when the basis disappears. Something must be done.</p><p>\\\nFor the record, we don't know what happened when BitMEX invented perpetual futures but since these contracts are sometimes referred to as perpetual swaps, one can only assume that they decided to borrow a mechanism from swap contracts - an agreement between two parties to exchange cash flow, typically used to hedge the risk of oscillating loan interest rates or to exchange value between two positions.</p><p>\\\nWith this mechanism, perpetual futures buyers and sellers must exchange cash flow (making 'funding payments') with each other based on the difference between the underlying's futures price and spot price. If the futures price is higher (the underlying trading at a premium), the buyers have outbought the sellers. At such times, the funding rate mechanism dictates buyers must pay sellers based on their position size. This way, sellers will have enough reason to hold on to their short positions and buyers will have their accounts bled dry if they keep their long positions open indefinitely.</p><p>The reason we spent hundreds of words talking about perpetual futures in an article dedicated to options is that we wish to demonstrate how removing a seemingly insignificant variable (expiry date) from a financial instrument could lead to starking imbalances in the market and take some of the most innovative minds to fix it by introducing a new mechanism.</p><p>Options are quite like futures, except futures contracts impose on both parties the obligation to transact a certain asset at a given time, whereas options only give them the right. You have the option to pocket your profit when your option is in the money (ITM), as well as throw it into the bin when it's out of the money (OTM).</p><p>\\\nAs such, futures contracts can be priced based on their entry price but options must charge a premium for signing this contract. This premium is the price a buyer pays a seller (writer) and options at each price tick form a market on their own. Buyers are free to choose the lowest ask they can find for a certain underlying at a certain strike price. Once again, removing one restraint (obligation to buy or sell) from a financial instrument leads to an entirely different derivative.</p><p>\\\nTraditional options already give investors immense flexibility for locking profits and hedging risks. You can hold a long position for an underlying while buying a put option of the same size for the same underlying at the same price. This way, if the price goes down, your long position is at a loss but the amount is only equal to your profit from the put option (or its seller), leaving you losing only the premium you paid for your put. If the price goes up, your long position stands to profit and you can throw your OTM put option in the bin.</p><p>\\\nAs you have seen, even options that expire are already much more complex than futures. Black, Scholes, and Merton won a Nobel Prize for developing a formula for stock options valuation. But what if we take it a step further and remove the expiry date from the options, like what we did to futures?</p><p>There are two approaches that have our attention. One was proposed by Paradigm and the notorious Sam Bankman-Fried in their research titled '<a href=\"https://www.paradigm.xyz/2021/05/everlasting-options\">Everlasting Options</a>', and the other by Panoptic.</p><h3>Everlasting options: A universal funding model for efficient liquidity and arbitrage</h3><p>In this paper, the authors proposed a universal funding mechanism for derivatives based on the difference between mark price and index price of the underlying (for futures) or the contract itself (for options). This is a generalised version of the perpetual futures funding mechanism and backed by the no-arbitrage pricing model that where there is a potential profit, there will be arbitrageurs to make the most of it. In the case of perpetual futures, buyers will pay sellers when the mark price is higher than the spot price or in the case of everlasting options, when the mark price is higher than the potential payoff.</p><p>\\\nThis universal mechanism is playing the arbitrageuers and such activities are ideal for centralized exchanges since the calculations and payments can be made within milliseconds by their complex trading engine running on mega servers. Indeed, the authors mentioned the traditional crypto options market being a nightmare (in our own words) for market makers because there are just so many markets to make. Their everlasting options are equivalent to a basket of options with different expiration times and weights equal to the inverse of 2 to the power of the number of funding cycles before the expiration time. This way, market makers can concentrate their liquidity on these baskets instead of spreading it on 100 markets.</p><p>\\\nBut the thing is, no one said options can only be traded on centralized exchanges with large institutions as market makers/liquidity providers. A decentralised ecosystem calls for decentralised protocols, and mechanisms that are less costly and cumbersome for smart contracts.</p><h3>Panoptions: A Uniswap-inspired, oracle-free revolution</h3><p>Enter Panoptic with their perpetual options ('<a href=\"https://paper.panoptic.xyz/\">Panoptions</a>'). By comparing a put option to a Uniswap V3 liquidity pool, they proposed this on-chain option that never expires.</p><p>\\\nUniswap V3 pools allow liquidity providers to deposit 2 assets and earn fees when the price ratio between these 2 assets is within a certain range. When it's out of the range, your liquidity becomes 100% of the asset with the lower price. Panoptic put options are essentially concentrated liquidity deployed on a single price point - its strike price. Let's pretend you hold an ETH-USDT Panoptic put option. When ETH's price goes above the strike price, this put option is OTM and becomes 100% USDT. When ETH's price is below the strike price, the buyer can give 1 ETH to the seller in exchange for all the USDT in the pool, earning the difference between the strike price and the price they paid for that 1 ETH.</p><p>\\\nPanoptic call options work exactly the same except the 2 assets must switch places.</p><p>\\\nBut that's only half the formula. We still need to price the Panoptions by putting a premium on them. In contrast to traditional options, Panoptions charge no premium upfront and assume that the value of options can be realised over time.</p><p>\\\nMeet θ, a Greek letter used to define the rate of an option's value decline over time. If you studied derivatives (the mathematical one), you would know the derivative of mileage over time is velocity - the rate/speed of your mileage increase over time. And by integrating the speed over time, you get mileage. Theoretically, the same goes for options: if we integrate θ, the 'value speed', over time, we get value.</p><p>We are able to do this because there is another formula for θ instead of doing derivatives:</p><p>\\\nWhere S denotes the underlying asset spot (or current) price, σ is the asset’s volatility, K is the strike price, and t is the time to expiration.</p><p>\\\nNote this formula is flawed since we assumed a 0 risk-free interest rate when in reality it can get quite higher. But how high? Should we take the interest rate from Binance Earn, ETH staking, Aave Lend, or heaven forbid, treasury bonds? This question may take an industry to answer.</p><p>\\\nThe good news is, we still haven't said a word about oracles because by tethering Panoptions to the corresponding Uniswap V3 pool, this system won't ever need an oracle as long as there are enough traders swapping tokens via this pool.</p><p>\\\nThis way, we have a simulated option on smart contracts, a premium that is price path dependent but oracle-free, and some solid knowledge in derivatives, both financial and mathematical. We are probably more ready than 99.9% of individuals on earth to trade options.</p><h2>Perpetual options on-chain</h2><p>Panoptic built an entire options trading ecosystem with smart contracts. Participants are divided into liquidity providers, option sellers, and option buyers.</p><p>\\\nBefore anyone can do anything, liquidity providers must first deposit assets into a liquidity pool. Sellers and buyers must also deposit their collateral. Sellers need to first mint their call or put option by paying a 0.1% commission and locking up (borrowing) a certain amount of liquidity at a strike price. Then, buyers can buy these options by paying the same rate of commission, locking up some more liquidity, and minting their position.</p><p>\\\nSince our premium is accumulated over time, there should be 0 premium when the option was just sold. Instead, sellers would be credited a streaming premium every time the spot price crosses the strike price.</p><p>\\\nWhen exercising their options, buyers will pay back their borrowed liquidity plus premium while getting the numeraire (for put options) or the underlying asset (for call options).</p><p>\\\nOn one hand, Panoptions is genius. By synthesising options with Uniswap V3 pools and settling premium when the option is exercised, the entire process is moved onto the blockchain. Anyone can access these financial instruments as long as they know their way around wallets and smart contracts. Under the ERC-1155 token standard, you can mint several options into one token for further risk and volatility customisation or even duplicate a composition someone else just shared.</p><p>\\\nOn the other hand, since Panoptions can be minted at 0 premium and a 0.1% fee, who's to stop arbitrageurs from buying ITM options before immediately exercising them for guaranteed profit? After a few costly lessons, who's to encourage sellers into minting ITM positions only to lose money? With only OTM options, the market will be as bustling as an empty bucket.</p><h2>Finding the f(law) in funding &amp; finance</h2><p>That's not to say the centralised approach has no flaw. The universal funding mechanism can be perfect if the funding is calculated and implemented every nanosecond. But when the funding cycle is stretched to 8 hours, a lot of things can happen right before and after funding payments are made. People may open a position 0.01 seconds before funding and close it immediately after receiving funding payments, leading to abnormal fluctuations around the time of funding.</p><p>\\\nIf we take a step back, the funding mechanism is merely a bandaid slapped onto someone with a headache that is CEX-traded crypto options. The real hurdle that is holding so many exchanges back from introducing options is the lack of liquidity.</p><p>\\\nWhen you first look at it, crypto options seem a good instrument boasting similar open interest to perpetual futures:</p><p>\\\nWhen in reality, the options market is divided into hundreds of sub-markets, each with a different expiration, strike price, and supply &amp; demand. As a result, liquidity is fragmented into dozens of pieces and the spread on some sub-markets can be jaw-dropping. And that's just Bitcoin. Go to Bybit, the 2nd/3rd CEX, and look for options for Solana, the 4th largest crypto (not counting stablecoins) looking to surpass Ether, you'll find almost half of the sub-markets empty. Options are just too complex for investors without a systematic understanding of finance and investing, at least at first glance. It's not even friendly to market makers, as mentioned in Path dependency.</p><p>\\\nLooks like we must educate all traders about the benefits of options and invite them to trade these fine instruments. Markets can be made as long as there are enough traders. But that's just another bandaid on an even grimmer headache.</p><p>\\\nIf you're looking to trade crypto derivatives, there are 2 places to go: CEX and DEX. CEXs are generally faster with more liquidity but you must go through an arduous KYC process and put your funds in the hands of others. DEXs give you more control and freedom but are not nearly as fast or efficient as CEXs. At its current state, blockchain will never be an ideal place for sophisticated or institutional traders commanding huge liquidity who would choose speed over decentralisation and permissionlessness any day. Many DEXs will look to centralise 1 or several links in their protocol such as order book, order matching engine, database, market makers and more to maximize efficiency and attract large institutions with deep pockets. As a result, centralised institutions will have more and more say in these protocols and in the end, they may just turn into on-chain CEXs where decentralisation is nothing but a name.</p><p>\\\nSuch is the finance industry. When even the slightest edge may put you ahead and rake in billions of dollars, the survivors will look to build higher and higher walls and work with players from all walks to protect their interests. To a newcomer, the world of finance is as much <a href=\"https://www.paradigm.xyz/2020/08/ethereum-is-a-dark-forest\">a dark forest as Ethereum</a> is although neither was designed to be initially. Uninitiated individuals will always get eaten alive in such a hostile environment while the survivors feed on their remains and grow into behemoths that are too big to fall. In the end, these financial giants will have immense fun playing with sophisticated, quadruple synthesised products like MBS in an extremely centralised walled garden while the outsiders will do anything for an entry pass.</p><p>\\\nSatoshi Nakamoto did invent Bitcoin to battle centralisation but now, the cryptocurrencies may just become another place where institutions take in individuals' funds and throw them one or two bones every now and then.</p><p>But the future is not all doom and gloom. There surely will be more brilliant minds trying to innovate on perpetual options and evangelising this financial instrument. Options that favour long-term investors with minimal arbitraging opportunities may be invented and blockchain is just an ideal place for them. Account abstraction may eventually bring in hundreds of millions of new users and with them, fragmented liquidity may not be a problem any more. Traders who value decentralisation and privacy will still get to play and grow their own games. A few boutique protocols may survive through the years and eventually be discovered by the masses.</p><p>\\\nLooking back, perpetual options may not even be the right answer we are looking for. They are one of the most important derivatives with a spark of crypto innovation but at its current state, it's merely a derivation from a traditional financial instrument that is as far from decentralisation as an empty bucket. To disrupt the old finance, we may need to build a new one from the ground up.</p><p><strong><em>A version of this article was originally published&nbsp;.</em></strong></p>","contentLength":16826,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google Chrome May Soon Use 'AI' To Replace Compromised Passwords","url":"https://it.slashdot.org/story/25/02/11/1952248/google-chrome-may-soon-use-ai-to-replace-compromised-passwords?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739304900,"author":"msmash","guid":290,"unread":true,"content":"Google's Chrome browser might soon get a useful security upgrade: detecting passwords used in data breaches and then generating and storing a better replacement. From a report: Google's preliminary copy suggests it's an \"AI innovation,\" though exactly how is unclear. \n\nNoted software digger Leopeva64 on X found a new offering in the AI settings of a very early build of Chrome. The option, \"Automated password Change\" (so, early stages -- as to not yet get a copyedit), is described as, \"When Chrome finds one of your passwords in a data breach, it can offer to change your password for you when you sign in.\" \n\nChrome already has a feature that warns users if the passwords they enter have been identified in a breach and will prompt them to change it. As noted by Windows Report, the change is that now Google will offer to change it for you on the spot rather than simply prompting you to handle that elsewhere. The password is automatically saved in Google's Password Manager and \"is encrypted and never seen by anyone,\" the settings page claims.","contentLength":1052,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google says it removed cultural events from its calendar last year","url":"https://techcrunch.com/2025/02/11/google-says-it-removed-cultural-events-from-its-calender-in-mid-2024/","date":1739304300,"author":"Dominic-Madori Davis","guid":147,"unread":true,"content":"<p>Google has removed events such as Black History Month and Pride Month from being listed on the calendar by default.&nbsp; Other events that were removed from the default calendar include Jewish Heritage, Indigenous People Month, Holocaust Remembrance Day, and Hispanic Heritage Month.&nbsp; Google spokesperson Madison Cushman Veld confirmed the changes to TechCrunch, saying that in […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":444,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Anduril takes control of Microsoft’s $22B VR military headset program","url":"https://techcrunch.com/2025/02/11/anduril-takes-control-of-microsofts-22b-vr-military-headset-program/","date":1739304207,"author":"Julie Bort","guid":146,"unread":true,"content":"<p>The Army plans to grant upstart weapons maker Anduril control of one of its highest-profile and long-troubled projects known as the Integrated Visual Augmentation System (IVAS) pending final Department of Defense (DoD) approval, founder Palmer Luckey announced in a blog post Tuesday. IVAS was initially awarded to Microsoft in 2018 to develop augmented reality headsets […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":439,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tumblr to join the fediverse after WordPress migration completes","url":"https://techcrunch.com/2025/02/11/tumblr-to-join-the-fediverse-after-wordpress-migration-completes/","date":1739303100,"author":"Sarah Perez","guid":145,"unread":true,"content":"<p>Since 2022, blogging site Tumblr has been teasing its plans to integrate with the fediverse — the open social web powered by the protocol ActivityPub also used by Mastodon, Threads, Flipboard, and others. Now, the Automattic-owned blogging platform is sharing more information about when and how that integration could actually happen. As it turns out, […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":423,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FTC Fines DoNotPay Over Misleading Claims of 'Robot Lawyer'","url":"https://slashdot.org/story/25/02/11/1932223/ftc-fines-donotpay-over-misleading-claims-of-robot-lawyer?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739302500,"author":"msmash","guid":289,"unread":true,"content":"The U.S. Federal Trade Commission has ordered DoNotPay to stop making deceptive claims about its AI chatbot advertised as \"the world's first robot lawyer,\" in a ruling that requires the company to pay $193,000 in monetary relief. The final order, announced on February 11, follows FTC charges from September 2024 that DoNotPay's service failed to match the expertise of human lawyers when generating legal documents and giving advice. \n\nThe company had not tested its AI's performance against human lawyers or hired attorneys to verify the accuracy of its legal services, the FTC said. Under the settlement, approved by commissioners in a 5-0 vote, DoNotPay must notify customers who subscribed between 2021 and 2023 about the FTC action and cannot advertise its service as equivalent to a human lawyer without supporting evidence.","contentLength":831,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Musk’s $97.4B bid could gum up OpenAI’s for-profit conversion","url":"https://techcrunch.com/2025/02/11/how-musks-97-4b-bid-could-gum-up-openais-for-profit-conversion/","date":1739302200,"author":"Maxwell Zeff, Kyle Wiggers","guid":144,"unread":true,"content":"<p>On Monday, Elon Musk, the world’s richest man, offered to buy the nonprofit that effectively governs OpenAI for $97.4 billion. The unsolicited buyout would be financed by Musk’s AI company, xAI, and a consortium of outside investors, per a letter sent to California and Delaware’s attorneys general. OpenAI CEO Sam Altman quickly dismissed Musk’s bid, […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":428,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hackers Call Current AI Security Testing 'Bullshit'","url":"https://it.slashdot.org/story/25/02/11/191240/hackers-call-current-ai-security-testing-bullshit?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739300460,"author":"msmash","guid":288,"unread":true,"content":"Leading cybersecurity researchers at DEF CON, the world's largest hacker conference, have warned that current methods for securing AI systems are fundamentally flawed and require a complete rethink, according to the conference's inaugural \"Hackers' Almanack\" report [PDF]. \n\nThe report, produced with the University of Chicago's Cyber Policy Initiative, challenges the effectiveness of \"red teaming\" -- where security experts probe AI systems for vulnerabilities -- saying this approach alone cannot adequately protect against emerging threats. \"Public red teaming an AI model is not possible because documentation for what these models are supposed to even do is fragmented and the evaluations we include in the documentation are inadequate,\" said Sven Cattell, who leads DEF CON's AI Village. \n\nNearly 500 participants tested AI models at the conference, with even newcomers successfully finding vulnerabilities. The researchers called for adopting frameworks similar to the Common Vulnerabilities and Exposures (CVE) system used in traditional cybersecurity since 1999. This would create standardized ways to document and address AI vulnerabilities, rather than relying on occasional security audits.","contentLength":1203,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"3DOS Expands Decentralized Manufacturing With Walrus-Powered AI And Storage","url":"https://hackernoon.com/3dos-expands-decentralized-manufacturing-with-walrus-powered-ai-and-storage?source=rss","date":1739299876,"author":"Chainwire","guid":202,"unread":true,"content":"<p>Palo Alto, USA, February 11th, 2025/Chainwire/--3DOS, the world’s first decentralized manufacturing network, has selected Walrus as its decentralized storage solution to power its expanding ecosystem of AI-driven manufacturing tools and 3D printing designs. Following last year’s announcement to build its network on Sui, this partnership cements 3DOS’s mission to decentralize and localize global manufacturing, ensuring supply chain resilience and accessibility.</p><h3>A Global Manufacturing Network Powered by AI</h3><p>As part of this vision, 3DOS is launching an  that scrapes and indexes global manufacturing capacity beyond 3D printing. The tool will collect real-time data on factories, CNC machining, injection molding, and other manufacturing services worldwide, giving instant access to local production options.</p><p>\\\nThis AI-driven database will be securely stored on Walrus’s decentralized storage network, making it tamper-proof, censorship-resistant, and accessible globally. By integrating AI, decentralized storage, and on-demand manufacturing, 3DOS is building the largest open manufacturing index, enabling businesses and individuals to find and utilize local manufacturing resources instantly.</p><h3>Decentralized Storage: The Backbone of Decentralized Manufacturing</h3><p>Beyond AI-powered manufacturing discovery, 3DOS also enables users to upload, tokenize, and monetize 3D printing designs as NFTs on Sui, allowing others to pay for usage in their own manufacturing processes. Each tokenized design is immutably stored on Walrus, carrying metadata that enforces ownership and royalty rights for creators.</p><h3>Key Benefits of Walrus for 3DOS:</h3><ul><li>AI-powered manufacturing database, storing global manufacturing capacity beyond 3D printing.</li><li>Tamper-proof storage for 3D designs, preventing IP theft and ensuring integrity.</li><li>Censorship-resistant supply chain data, ensuring global access to manufacturer networks.</li><li>NFT-based digital twins, enabling on-chain verification of parts and automated royalty payments.</li><li>Global redundancy, enhancing supply chain resilience, and ensuring uninterrupted access to critical data.</li></ul><blockquote><p>\"Walrus gives 3DOS the decentralized, secure storage needed to power the future of global manufacturing. Together, we're making supply chains smarter, more resilient, and truly unstoppable,” said John Dogru, CEO of 3DOS.“</p></blockquote><blockquote><p>‘‘3DOS demonstrates the value of global coordination of different resources and the value of composing resources including DeFi, stored CDA designs, audits of manufacturing, and tokenized manufacturing capacity to revolutionize industry broadly,” said Rebecca Simmonds, Managing Executive of the Walrus Foundation. “Walrus is the storage platform that helps fulfill this vision.”</p></blockquote><p>\\\nWith Walrus and Sui as key infrastructure, 3DOS is set to redefine global manufacturing – connecting AI, decentralized storage, and tokenized designs to decentralize and localize production like never before.</p><p>3DOS is building the world's largest decentralized on-demand manufacturing network, enabling users to upload designs, earn royalties, and produce goods globally. Using blockchain technology, 3DOS ensures secure, royalty-protected transactions, eliminating inventory costs and middlemen.</p><p>:::tip\nThis story was distributed as a release by Chainwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":3346,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Toshi.bet Expands Crypto Gaming Platform With Personalized Rewards And Instant Withdrawals","url":"https://hackernoon.com/toshibet-expands-crypto-gaming-platform-with-personalized-rewards-and-instant-withdrawals?source=rss","date":1739299311,"author":"Chainwire","guid":201,"unread":true,"content":"<p>BVI, BVI, February 11th, 2025/Chainwire/--Toshiba.bet, a growing crypto gaming platform, continues its expansion with a focus on instant withdrawals, privacy-focused gaming, a personalized rewards system, and an extensive selection of gaming options.</p><p>\\\nDesigned for crypto users seeking a seamless and flexible gaming experience, Toshi.bet introduces features aimed at enhancing user engagement and accessibility.</p><h3>Instant Withdrawals and Diverse Gaming Options</h3><p>Toshi.bet provides instant withdrawals, enabling players to access their funds without delays. The platform hosts a wide range of gaming options, including slots, live dealer games, and crypto-based experiences, positioning itself as a comprehensive destination for online gaming with cryptocurrency.</p><h3>A Personalized Approach to Rewards</h3><p>The platform differentiates itself through a personalized rewards system, offering customized incentives based on individual gaming preferences. Instead of standardized bonuses, users receive tailored VIP perks, cashback offers, and other benefits designed to enhance engagement and retention.</p><h3>Key Features of Toshi.bet</h3><ul><li>Rapidly growing online crypto gaming platform</li><li>Customized rewards and incentives tailored to individual users</li><li>Instant withdrawals for fast and efficient payouts</li><li>A wide selection of games, including slots, live dealers, and crypto-focused titles</li><li>A secure gaming environment with crypto-powered transactions</li></ul><h3>Expanded Cryptocurrency Support</h3><p>In line with its commitment to crypto accessibility, Toshi.bet supports transactions with a variety of digital assets, including both major cryptocurrencies and meme coins. The platform facilitates deposits and withdrawals in BTC, ETH, USDT, BNB, and XRP, as well as community-driven tokens such as DOGE, SHIB, PEPE, and FLOKI.</p><p> is a crypto gaming platform offering a diverse range of casino games, instant withdrawals, and a personalized rewards system.</p><p>\\\nDesigned for flexibility and accessibility, Toshi.bet supports multiple cryptocurrencies and prioritizes a seamless gaming experience. The platform aims to provide a secure and transparent environment for crypto enthusiasts worldwide. For more details, users can visit .</p><p>:::tip\nThis story was distributed as a release by Chainwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":2304,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GameFrog ($GMF) Introduces AI-Driven Staking Model And Security-Focused Smart Contract Audit","url":"https://hackernoon.com/gamefrog-$gmf-introduces-ai-driven-staking-model-and-security-focused-smart-contract-audit?source=rss","date":1739299141,"author":"Chainwire","guid":200,"unread":true,"content":"<p>GameFrog($GMF)a new entrant in the memecoin sector, integrates artificial intelligence-driven market strategies with a staking rewards system.</p><p>\\\nDrawing inspiration from the cultural influence of GameStop and the Pepe the Frog meme, the project aims to offer token holders automated staking mechanisms and liquidity management tools. With the presale nearing $250,000, participants are acquiring $GMF tokens at presale prices before public trading begins at $0.10 per token.</p><h3>Key Features of GameFrog ($GMF)</h3><p>GameFrog incorporates AI-powered market optimization and staking functionalities, with a focus on sustainability and liquidity support.</p><ul><li><p>Presale Model: GameFrog’s presale phase has reportedly raised close to $250,000, with an initial token launch price of $0.10 per $GMF.</p></li><li><p>Staking Rewards: The project advertises staking incentives, with mechanisms designed to automate rewards distribution.</p></li><li><p>AI-Powered Liquidity Management: The Deepseek AI Agent is programmed to monitor market conditions and adjust liquidity strategies.</p></li><li><p>Liquidity Allocation: A portion of presale funds is designated for liquidity support to maintain market stability.</p></li><li><p>Security Audit: An audit conducted by Coinsult found no critical security issues, with measures implemented to prevent unauthorized token minting.</p></li></ul><h3>Smart Contract and Security Measures</h3><p>The GameFrog development team has placed a strong emphasis on security from the very start. An audit conducted by  no critical issues, confirming that GameFrog’s smart contract is built with robust safeguards—including measures to prevent unauthorized token minting—and does not incorporate honeypot features or blacklisting functions. This commitment to security ensures a transparent and trustworthy investment experience.</p><h3>Staking and AI-Driven Optimization</h3><p> staking model is structured for automated reward distribution. According to the project, rewards accumulate daily and can be claimed following the presale period. The Deepseek AI system is designed to optimize token liquidity and mitigate price volatility.</p><p>The GameFrog presale is currently open, with participation available through:</p><p> is a memecoin project that integrates AI-based market stabilization tools and staking functionalities. The project aims to combine community engagement with algorithmic market optimization.</p><p>:::tip\nThis story was distributed as a release by Chainwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":2445,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SEDA's Flagship Verification Module To Secure A $120 Billion Industry","url":"https://hackernoon.com/sedas-flagship-verification-module-to-secure-a-$120-billion-industry-eb8waku?source=rss","date":1739298523,"author":"Chainwire","guid":199,"unread":true,"content":"<p>NEW YORK, New York, February 11th, 2025/Chainwire/--SEDA has announced the Interoperability Verification Module (IVM) framework to set an industry standard for cross-chain verification for all routes, across any VM.</p><p>\\\nToday,  announced the first-of-its-kind  framework. SEDA IVMs are a plug-and-play verification solution for interoperability protocols, adding significantly upgraded security, near-instant horizontal scaling, and increased decentralization out of the box.</p><p>\\\nInteroperability providers integrating the SEDA IVM can access a hyper-specialized framework for independent, permissionless verification of any cross-chain transaction across all routes. </p><p>\\\nThe  leverages a multi-layer verification process consisting of an independent overlay network, decentralized solvers, and a combination of private and public RPC data providers. With , the SEDA IVM presents a critical piece of industry-needed security infrastructure. </p><p>\\\nBuilt to offer a robust, scalable, and customizable module, the IVM provides independent decentralized verification for millions of transactions across thousands of networks.</p><h3>Key features and benefits of the SEDA IVM include:</h3><ul><li>Industry-wide data parity with a singular security zone.</li><li>Built-in liveness guarantees.</li><li>Programmable design to suit specific needs of bridge, solver, and abstraction layers.</li><li>Permissionless access and deployments.</li></ul><blockquote><p>\"The demand for robust interoperability infrastructure has surged as users and developers engage with hundreds of specialized networks,\" said Peter Mitchell, CEO and Co-founder of SEDA. </p></blockquote><p>\\\n\"Over the last two years, the interoperability sector has expanded dramatically, achieving a transaction volume of over $123 billion in 2024. Projections indicate this sector could reach over $250 billion in 2025. Our IVMs represent a significant advancement for Interop 3.0, allowing any interoperability provider to customize parameters within the SEDA IVM framework, ensuring independent verification across all routes through a single deployment.\"</p><p>\\\nParallel to a message relayed between chains, the IVM automatically initiates a secure verification sequence, in which a dedicated secret committee of independent overlay nodes is formed to query RPC data on the source chain. </p><p>\\\nResults are returned via a commit-reveal scheme for data integrity and preventing manipulation, after which protocol-defined instructions filter and order results before being batched on SEDA's main chain. </p><p>\\\nData results are secured with tamper-proof cryptographic guarantees before being relayed by solvers to the destination chain.</p><p>\\\nBy plugging into SEDA’s distributed verification architecture, interoperability providers inherit security and liveness guarantees associated with SEDA’s Network design, consisting of a performant layer one, a highly decentralized overlay network, and a censorship-resistant solver network.</p><p>\\\nThis design mitigates collusion risk and downtime commonly associated with default multi-sig relay setups, which secure over </p><p>By decoupling verification, interoperability providers can focus on scaling services to thousands of new chains, allowing SEDA to provide specialized verification for all routes.</p><p> is a programmable oracle infrastructure that enables builders on any network to connect application-specific data feeds in seconds.</p><p>:::tip\nThis story was distributed as a release by Chainwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":3440,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Only One Big Economy Is Aiming for Paris Agreement's 1.5C Goal","url":"https://news.slashdot.org/story/25/02/11/1815209/only-one-big-economy-is-aiming-for-paris-agreements-15c-goal?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739297640,"author":"msmash","guid":287,"unread":true,"content":"Seven of the 10 world's largest economies missed a deadline on Monday to submit updated emissions-cutting plans to the United Nations -- and only one, the UK, outlined a strategy for the next decade that keeps pace with expectations staked out under the Paris Agreement. From a report: All countries taking part in the UN process had been due to send their national climate plans for the next decade by Feb. 10, but relatively few got theirs in on time. Dozens more nations will likely come forward with updated plans within the next nine months before the UN's annual climate summit, known as COP30, kicks off in Brazil. \n\nThe lack of urgency among the more than 170 countries that failed to file what climate diplomats refer to as \"nationally determined contributions\" (NDCs) adds to concerns about the world's continuing commitment to keeping warming to well below 2C, and ideally 1.5C, relative to pre-industrial levels. Virtually every country adopted those targets a decade ago in the landmark agreement signed in Paris, but a series of lackluster UN summits last year has added to a sense of backsliding. US President Donald Trump has already started the process of pulling the world's second-largest emitter out of the global agreement once again. Political leaders in Argentina, Russia and New Zealand have indicated they would like to follow suit.","contentLength":1357,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Klarna and Deel eye IPOs, and Stripe embraces crypto","url":"https://techcrunch.com/2025/02/11/more-fintech-startups-are-planning-ipos-embracing-crypto/","date":1739297220,"author":"Mary Ann Azevedo","guid":143,"unread":true,"content":"<p>Welcome to TechCrunch Fintech!&nbsp; This week we’re looking at how fintech heavyweights such as Klarna and Stripe are incorporating crypto into their strategies, which companies are planning for IPOs, one fintech’s Super Bowl ad, Stripe’s new lead of startups and venture capital, and more! To get a roundup of TechCrunch’s biggest and most important fintech […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":432,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Healthy Competition With GCC 15 vs. LLVM Clang 20 Performance On AMD Zen 5","url":"https://www.phoronix.com/review/clang20-gcc15-amd-znver5","date":1739296980,"author":"Michael Larabel","guid":714,"unread":true,"content":"<article>In the recent discussion over the GNU Gold linker being deprecated, there was the usual LLVM vs. GCC compiler/toolchain debate. Fortunately, with recently working on some initial benchmarks of the GCC 15 compiler I was following that up with some fresh LLVM Clang compiler comparison metrics on the same AMD Zen 5 hardware.</article>","contentLength":323,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple brings heart rate monitoring to Powerbeats Pro 2","url":"https://techcrunch.com/2025/02/11/apple-brings-heart-rate-monitoring-to-powerbeats-pro-2/","date":1739296800,"author":"Brian Heater","guid":142,"unread":true,"content":"<p>Apple Tuesday announced the long-awaited debut of Powerbeats Pro 2 earbuds. The new headphones arrive nearly six years after the original Powerbeats hit the market. The new model maintains the familiar ear hook for workouts, while delivering upgraded sound, better battery life, and a wireless charging case. The earbuds also mark a major next step […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":417,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lost Hard Drives, Meme Coins, and Million-Dollar Gambles: Lessons From Crypto's Biggest Winners","url":"https://hackernoon.com/lost-hard-drives-meme-coins-and-million-dollar-gambles-lessons-from-cryptos-biggest-winners?source=rss","date":1739296543,"author":"Vlad Hryniv","guid":198,"unread":true,"content":"<p>The crypto space is constantly evolving, and along with it come the stories of people who are increasing their wealth here. But what is behind their success? How did the leading crypto investors, traders, and entrepreneurs achieve their results in this field? In today's article, we will look at the most high-profile success stories that have become an example for other investors and analyze the key factors that allowed them to achieve such impressive results.</p><h3><strong>The First Step to Success: Early Investments</strong></h3><p>Probably everyone in the industry has heard stories at least once about a guy who sold his 10,000 Bitcoins for 2 pizzas, or someone who accidentally threw away a hard drive with 8,000 BTC on it. But have you heard the  of the man who accidentally became a Bitcoin millionaire?</p><p>\\\nWell, the hero of the story is Kristoffer Koch, a Norwegian engineer who, in 2009, had no idea that his academic curiosity would turn him into a cryptocurrency millionaire. When the price of 1 Bitcoin was even less than $1, Koch was working on his dissertation on encryption. Interested in the potential of the decentralized digital currency, he decided to invest $22-$27, purchasing approximately 5000 BTC. At the time, Bitcoin was unpopular, so Koch's investment was more of a technical study than a financial one. Immediately afterward, the man forgot about his small investment and lived his usual life, not paying attention to the changes around digital assets.</p><p>\\\nHowever, everything changed in 2013, when the price of the first cryptocurrency experienced a significant jump, attracting the attention of many investors. So, when all the headlines in the media were about Bitcoin and its $200 price, the engineer remembered his long-forgotten investment. When he accessed his wallet, he discovered that his wealth was about $886,000. However, Koch did not succumb to the madness of his newfound wealth but made a practical decision by purchasing a new apartment for a portion of his Bitcoins.</p><p>\\\nGiven his story, two main strategies led to a successful outcome. The first is the initial coin offering (ICO), when investors invest in projects at the start-up stage, allowing them to make a significant profit if they are successful. The second, albeit random, in his case is HODL. The essence of this strategy is to buy cryptocurrencies for long-term storage in anticipation of a significant increase in value.</p><h3>From $30 a Day to a Million: How the DCA Strategy Changed the Investor's Life</h3><p>Another investment success story: a user with the nickname regothetrader turned a daily investment of $30 into a portfolio worth $1 million in almost 8 years. At the age of 22, he started his strategy of gradual Bitcoin purchases. Every 12 hours, regardless of the asset's exchange rate, Rego invested $30.</p><p>\\\nTalking about his  on social network X, he admitted that such discipline required personal sacrifice: <em>‘I sacrificed going out with my friends to allocate to this belief. I stayed home. I didn't buy a new car. I didn't buy fancy things. I kept it minimal.’</em></p><p>\\\nOn 13 November, he announced that his persistent DCA strategy had brought in $1,000,000 in 7 years, 10 months, and 12 days. In total, Rego has invested $86,370 in cryptocurrency.</p><p>\\\n<em>‘The truth is, Bitcoin is not a risk, it is a matter of understanding. The more you learn about it, the more obvious it becomes.’</em> the investor emphasized.</p><p>\\\nThe dollar-cost averaging (DCA) strategy involves spreading purchases over predetermined intervals, regardless of price. According to a  conducted by , 59% of investors use DCA as their primary investment strategy. Among the most common reasons they cite are hedging against market volatility, maintaining consistent investment habits, and eliminating emotions in trading.</p><h3>Know Your Product: The Role of Research and Knowledge</h3><p>Most of the success stories are about young investors, but one of the most incredible stories is about a teenager who started investing when he was just 12 years old.</p><p>\\\nErik Finman is an ordinary guy who managed to turn his Bitcoin investments into a huge fortune by the time he was 18. His family was not wealthy, but Eric's life changed when his grandmother gave him $1000. As he had always been interested in technology and innovation, he learned about Bitcoin in 2011. Seeing the potential of the new digital currency, Eric decided to invest his $1000 and bought his first Bitcoins with it. At that time, the world was skeptical about cryptocurrencies, and the asset itself was trading at only $12 per coin.</p><p>\\\nFor the next few years, Eric studied and gradually traded coins. At the age of 15, after falling out with his parents over his unwillingness to continue his studies at school, he decided to sell some of his investments. Having received $100,000, he invested it in his first business, which he started in his room. Finman really disliked going to school, so he created his own company, Botangle, where teachers conducted their classes online. After 2 years, he decided to sell his business for 300 BTC. So, when the first cryptocurrency rate exceeded $2700, 17-year-old Erik Finman became a millionaire.</p><p>\\\nLooking at Finman's story, one can understand that he used similar strategies as Koch. However, their approach to business was different. Finman was a curious guy, so he dove deep into the world of cryptocurrencies, learning everything he could about Bitcoin and blockchain technology. He didn't just invest blindly; he decided to research the market, study trends, and understand Bitcoin's full potential.</p><h3>Investors on the Wave: How the Launch of $TRUMP and $MELANIA Generated Million-Dollar Profits</h3><p>Following the recent inauguration of US President Donald Trump, the crypto industry has been rocked by a wave of new profit stories. The reason for this was the launch of the $TRUMP meme coin on 17 January. The value of the coin skyrocketed from $0.18 to $3.7 after the launch announcement. Within an hour of the launch, one trader managed to earn $20 million. According to  analysts, about 90 seconds after the announcement, the trader spent ~$1.1 million USDC, purchasing 5.97 million $TRUMP. A few hours later, these tokens were valued at over $116 million.</p><p>\\\nLater, the trader decided to distribute his assets among 10 different Solana wallets and began to gradually sell the coins the next day. According to the research company Bubblemaps, by the morning of Monday, January 20, he had  $85 million worth of TRUMP, leaving $75 million worth of tokens. However, this was not the end of his story, as First Lady Melania Trump followed her husband's example and issued her own meme coin, which was used by the trader. One of the wallets associated with the user bought a huge amount of MELANIA tokens a minute and a half after Melania's post on Truth Social. To finance the purchase of MELANIA, the trader sold $45 million worth of TRUMP, which led to a drop in the token's value of almost 50% on Sunday evening, according to Bubblemaps.</p><p>\\\nOther anonymous traders who made millions on the First Lady's tokens did not go unnoticed, either. One of them&nbsp;&nbsp;2,500 SOL ($688,000) to buy 5.2 million MELANIA for $0.13 and sold them four days later, earning a profit of 6208%, or $42.7 million.</p><p>\\\nThe stories of these anonymous traders once again emphasize the importance of early investment. But don't forget about one of the main risks - FOMO, the fear of missing out on an opportunity, which can force you to make unpredictable decisions that lead to large losses.</p><h3>How to Optimize Your Trading?</h3><p>Optimizing the crypto trading process is a key factor in increasing its efficiency and profitability. Therefore, the use of appropriate tools will help to make this process more convenient and efficient, as well as significantly simplify it.</p><p>Investing is a great opportunity to grow your capital, but beginners often encounter common mistakes that can be costly. Therefore, to minimize risks, you need to understand these mistakes and know how to avoid them.</p><p>A responsible approach, patience, and a willingness to constantly learn are some of the best allies in the crypto space. Avoid common mistakes and let your investments bring profit in the long run.</p>","contentLength":8163,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI CEO Sam Altman calls Musk’s bid an attempt to ‘slow us down’","url":"https://techcrunch.com/2025/02/11/openai-ceo-sam-altman-calls-musks-bid-an-attempt-to-slow-us-down/","date":1739295427,"author":"Kyle Wiggers","guid":141,"unread":true,"content":"<p>In an interview at the AI Action Summit in Paris on Tuesday, OpenAI CEO Sam Altman dismissed Elon Musk’s unsolicited $97.4 billion bid for OpenAI’s nonprofit as “an attempt to slow [OpenAI] down.” “[Musk] obviously is a competitor,” Altman said. “He’s raised a lot of money for [his AI company] xAI, and they’re trying to […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":408,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kickstarter Will Alert Backers When a Project Has Failed","url":"https://slashdot.org/story/25/02/11/1735222/kickstarter-will-alert-backers-when-a-project-has-failed?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739295300,"author":"msmash","guid":286,"unread":true,"content":"Crowdfunding platform Kickstarter will start notifying supporters when a fundraising campaign faces \"significant fulfillment failures\" and breaks the platform's rules. From a report: The notification will also inform supporters how it's addressing the issue, including by \"restricting the creator from launching future projects.\" \n\nThe update comes as part of a series of changes Kickstarter plans to make this year that are aimed at \"enhancing the backer experience and building trust in our community.\" Kickstarter has long faced challenges with scams and projects shutting down after raising thousands (or sometimes millions) of dollars, but this change should at least provide more transparency to backers.","contentLength":710,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stripe mulls employee shareholder sale at $85B-plus valuation","url":"https://techcrunch.com/2025/02/11/stripe-mulls-employee-shareholder-sale-at-85b-plus-valuation/","date":1739295175,"author":"Mary Ann Azevedo","guid":140,"unread":true,"content":"<p>Stripe is in talks for another shareholder sale that could value the company at “at least” $85 billion, according to multiple reports and a source familiar with the matter. The Information first reported the news that the payments infrastructure giant is working to sell employee-owned stocks. The move would help workers gain some liquidity as […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":417,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Built on Bluesky, Pinksky brings its Instagram-like app to Android","url":"https://techcrunch.com/2025/02/11/built-on-bluesky-pinksky-brings-its-instagram-like-app-to-android/","date":1739295000,"author":"Sarah Perez","guid":139,"unread":true,"content":"<p>Bluesky users on Android now have access to a new app that works more like Instagram than X. On Tuesday, an app called Pinksky launched an Android version of its photo-centric social networking experience built on top of Bluesky. The app is now one of many attempting to court former Instagram users by offering a […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":382,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Whale Casino Introduces Battlepass Season 1 With New Features And Rewards","url":"https://hackernoon.com/whale-casino-introduces-battlepass-season-1-with-new-features-and-rewards?source=rss","date":1739294878,"author":"Chainwire","guid":197,"unread":true,"content":"<p>WILLEMSTAD, Curaçao, February 11th, 2025/Chainwire/--Whale Casino, a platform in the crypto gaming sector, announces the launch of its innovative Battlepass for Season 1. This feature enhances how players interact with the casino, integrating gaming with access to a range of additional features within the platform.</p><h3>Whale Casino Expands Gamification with Battlepass</h3><p>The introduction of the Battlepass signifies a leap forward in the gamification of casino experiences. Designed to enhance user engagement, Battlepass Season 1 at Whale Casino offers an array of exclusive features and rewards, presenting users with new ways to maximize their gaming experience and explore potential benefits within the platform.</p><h3>Key Features and Benefits of the Whale Casino Battlepass:</h3><ul><li>LOOTBOXES: With the Battlepass, players can access several loot boxes that are filled with mystery rewards. These could range from bonus spins, and additional credits, to rare collectibles.</li></ul><ul><li>Tribes: Players can create or join Tribes and engage with streamers, unlocking Tribe-specific challenges and additional participation-based bonuses that enhance social and competitive elements.</li></ul><ul><li>Exclusive Whale Merch: Battlepass holders have the opportunity to claim limited-edition merchandise, including apparel and casino-themed accessories.</li></ul><ul><li>$Whale Tokens: The Battlepass integrates with the upcoming Whale Token, allowing holders to receive tokens that can be used within the platform for various benefits. As Whale Token becomes part of Whale Casino, this integration adds new engagement opportunities.</li></ul><ul><li>Battlepass Rewards and Bonuses: Season 1 includes a range of exclusive bonuses, such as daily, weekly, and seasonal rewards, free spins, cashback offers, and other platform-specific benefits.</li></ul><p>\\\nAdvantages of the Whale Casino Battlepass</p><p>The Battlepass introduces new ways to engage with the platform, offering added features and exclusive benefits. Key reasons to explore the Battlepass include:</p><ul><li>Enhanced Security and Transparency: By leveraging blockchain technology, every reward, transaction, and interaction within the Battlepass system is secure, transparent, and verifiable, ensuring fairness and trust.</li></ul><ul><li>Gamification at Its Best: The Battlepass transforms routine casino gaming into an engaging journey. With levels to conquer, challenges to overcome, and opportunities to unlock rewards, players can explore more of what Whale Casino has to offer.</li></ul><ul><li>Community and Competition: The Tribe feature encourages a sense of belonging and competition among players, making gaming a more social and dynamic experience.</li></ul><ul><li>Economic Incentives: The integration with $Whale Tokens introduces additional utility within the platform, creating opportunities for token-based benefits. As demand and usage grow, the token's role in the gaming ecosystem may expand, adding a financial dimension to participation.</li></ul><ul><li>Exclusive Content and Early Access: Battlepass holders get first dibs on new games, early access to updates, and exclusive content that isn't available to non-pass holders.</li></ul><h3>The Future with Whale Token</h3><p>Looking ahead, the  is poised to become a staple in the ecosystem of Whale Casino. Beyond serving as a reward mechanism in the Battlepass, it will also facilitate various transactions including gameplay, entry into special tournaments, and even governance in future community decisions about the platform's direction.</p><p>\\\nThe Battlepass marks the initial phase of Whale Token’s integration, offering a connection between gaming and cryptocurrency within the platform.</p><h3>Battlepass Season 1 Brings New Engagement Opportunities</h3><p>Battlepass Season 1 introduces new ways to interact with the Whale Casino platform, incorporating exclusive features and reward mechanisms. This addition connects gaming with digital assets, expanding opportunities within the casino ecosystem.</p><p>\\\nMore information on the Battlepass and its features is available at .</p><p> is at the forefront of merging traditional casino gaming with blockchain technology, providing a secure, transparent, and gaming environment filled with reward opportunities.</p><p>\\\nWith a focus on community, innovation, and player satisfaction, Whale Casino aims to set new standards in the online gaming world while offering Daily Cashback, the highest RTP, and instant payments without any gas fees.</p><p>\\\nUsers can discover the future of Whale Casino and $WHALE token by checking them out here:</p><p>:::tip\nThis story was distributed as a release by Chainwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":4510,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Jashita Tulum Expands Luxury Hospitality With Digital Asset Payments","url":"https://hackernoon.com/jashita-tulum-expands-luxury-hospitality-with-digital-asset-payments?source=rss","date":1739294222,"author":"Chainwire","guid":196,"unread":true,"content":"<p>Tulum, México, February 11th, 2025/Chainwire/--After serving as a discreet sanctuary for some of crypto's most influential figures— including founders of leading Layer 2 protocols, DeFi innovators, and privacy-focused project leaders —  has announced its new digital assets payment service.</p><p>\\\nWith a user-friendly interface, guests can now seamlessly make a reservation by paying with crypto directly through the hotel's official website, completing transactions quickly and effortlessly.</p><p>\\\nAccording to the team, this decision emerged from countless late-night conversations on their private beach with crypto visionaries who've made Jashita their second home. These leaders, whose protocols collectively manage billions in TVL, highlighted a crucial gap in luxury hospitality: The freedom to enjoy their digital wealth.</p><blockquote><p>\"When you've hosted the minds behind today's most revolutionary protocols, you learn what matters,\" says the company’s CEO Tommaso. “My ambition is not only to deliver magic moments to our guests, but also to welcome beautiful and innovative minds”.</p></blockquote><p>\\\nJashita introduces a luxury hospitality experience tailored for crypto-native travelers in one of the Caribbean’s premier destinations. This move positions Jashita as the first hotelier in Tulum to accept CryptoPayments directly through their booking system, aligning with the latest hospitality industry trends and catering to the evolving preferences of modern travelers.</p><p> is a beachfront luxury boutique hotel featuring 30 elegant suites, a stunning penthouse, an onsite Italian restaurant, and a serene spa. Nestled on Tulum’s most protected, and off-the-beaten-track bays: Soliman Bay.</p><p> rental homes designed for families, and groups. Located in La Privada, a gated luxury residential community within Aldea Zama, Tulum’s developing first luxury neighborhood, which offers guests a wide selection of restaurants, shopping, yoga studios, and markets. Guests can experience refined comfort in exclusive villas, offering a retreat that captures the best of Tulum.</p><p>Jashita Tulum Luxury Hotel and Villas</p><p>constanza@jashitahotel.com</p><p>:::tip\nThis story was distributed as a release by Chainwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":2251,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel CPU Microcode Updated For Five New Security Issues","url":"https://www.phoronix.com/news/Intel-Microcode-20250211","date":1739294128,"author":"Michael Larabel","guid":713,"unread":true,"content":"<article>Intel just published new CPU microcode for Alder Lake,  Emerald Rapids, Ice Lake, Raptor Lake, Sapphire Rapids, Sierra Forest, and other platforms going back to Coffee Lake H. There are five new security issues being addressed plus a number of different functional issues being resolved...</article>","contentLength":289,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Another person targeted by Paragon spyware comes forward","url":"https://techcrunch.com/2025/02/11/another-person-targeted-by-paragon-spyware-comes-forward/","date":1739293633,"author":"Lorenzo Franceschi-Bicchierai","guid":138,"unread":true,"content":"<p>Four people have so far come forward as victims of the Paragon spyware campaign targeting WhatsApp users, including one journalist and three activists. </p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What is an Altcoin Season (Altseason), and How Can You Benefit From It?","url":"https://hackernoon.com/what-is-an-altcoin-season-altseason-and-how-can-you-benefit-from-it?source=rss","date":1739293207,"author":"M-Media","guid":195,"unread":true,"content":"<h2><strong>What is an Altcoin season?</strong></h2><p>An altcoin season, or altseason, is a period when altcoins surge in value, surpassing Bitcoin in performance. An altcoin, or alternative coin, is a cryptocurrency that is not Bitcoin. Altseasons are usually driven by a shift in the liquidity of the crypto market.</p><p>\\\nDue to the bullish sentiments of the crypto market during pre-altseasons, investors tend to search for more profitable opportunities in the market, shifting their attention from Bitcoin (BTC) to other promising altcoins.</p><p>\\\nThis shift in investors' attention and interest often results in an increased flow of liquidity or money from Bitcoin to altcoins, causing their prices to rise, and their outperforming Bitcoin.</p><p>\\\nConversely, Bitcoin season is a period when Bitcoin outperforms altcoins. Due to Bitcoin’s status as digital gold, investors tend to shift their focus from altcoins to Bitcoin, especially when the market is bearish, resulting in the prices of altcoins falling significantly.</p><p>The first altseason occurred between 2017 and 2018. Bitcoin’s market dominance dropped significantly during this period, falling from 87% to 32%. Conversely, altcoins rose in value. This surge was a result of the ICO boom.</p><p>\\\nAn ICO, or Initial Coin Offering, is a fundraising method used by blockchain companies to finance their projects. A blockchain company often sells its tokens to investors in exchange for capital. The logic behind this was that these tokens' prices would rise upon the project's launch.</p><p>\\\nNotable ICOs launched during this period included Ethereum, Tron, and Polkadot. The ICO boom resulted in several altcoins reaching their all-time highs, including Ether (ETH), Ripple (XRP), and Litecoin (LTC). Conversely, Bitcoin experienced a significant decline, dropping from its peak price of over $20,000 to less than $6,000.</p><p>The next altseason occurred between 2020 and 2021. The opportunity to explore other aspects of blockchain technology was the main driver of this altseason. It was during this period decentralized finance (DeFi), non-fungible tokens (NFTs), and memecoins became popular.</p><p>\\\nAccording to , approximately $189 billion was locked in DeFi protocols by the end of 2021, a 767% increase over 2020.</p><p>\\\nThe NFT market also skyrocketed. According to , approximately $2.57 billion worth of NFT art was sold in 2021, up from $20 million in 2020, representing a 12,750% increase.</p><p>\\\nMemecoins were not left out, as meme tokens like Dogecoin (DOGE) and Shiba Inu (SHIB) gained significant popularity during this period.</p><p>\\\nAll these significantly affected the altcoin market, causing it to rise from 30% to 62%. The crypto market also reached an all-time high of $3 trillion. On the other hand, Bitcoin dominance dropped, falling from 70% to 30%.</p><h2><strong>Signs That an Altcoin Season Has Started</strong></h2><h3><strong>Increase in Altcoin Dominance</strong></h3><p>One major sign that an altcoin season has started is the increase in altcoin dominance, which is the percentage of the total crypto market cap made up of altcoins.</p><p>\\\nIt is calculated by subtracting Bitcoin dominance from 100%, that is:&nbsp;<em>Altcoin dominance = 100% – Bitcoin dominance</em>.&nbsp; You can get the Bitcoin dominance value in real-time by checking crypto aggregator sites like  and .</p><p>Trading volume is the total amount of a cryptocurrency that is traded (bought and sold) on a crypto exchange within a given time period.&nbsp; Due to the increase in the flow of liquidity from Bitcoin to altcoins, the trading volume of altcoins tends to increase during altseasons. Thus, an increase in the trading volume of altcoins is a good sign an altseason is about to begin.</p><h3><strong>Increase in Altcoin Season Index and Ethereum-to-Bitcoin Price Ratio (ETH/BTC)</strong></h3><p>\\\nThe altcoin season index is a metric used to determine how well altcoins outperform Bitcoin over a 30-, 60-, or 90-day period. Its value can be reliably used to predict if an altseason has started.</p><p>\\\nIf the altcoin season index is between 0 and 25, it indicates Bitcoin is dominating the crypto market. If it is between 25 and 75, it means the crypto market is experiencing a mixed performance.</p><p>\\\nIf, however, the altcoin season index is between 75 and 100, it means altcoins are outperforming Bitcoins, indicating an altseason.</p><p>\\\nThe ETH/BTC price ratio can also be used to determine an altseason. A rising ETH/BTC ratio means Ether (ETH) outperforms Bitcoin (BTC), a trigger that might lead to an altseason</p><h2><strong>How to Benefit From an Altcoin Season?</strong></h2><h3><strong>Research and Diversify Your Portfolio</strong></h3><p>Though altseasons can be profitable, they can also be risky, as a trader or investor might end up purchasing an altcoin that performs poorly. That’s why it’s important you research before investing in any altcoin.</p><p>\\\nTo begin your research, you can use website tools like Coinmarketcap and Coingecko to check the metrics of an altcoin, including its dominance, trading volume, and market cap.</p><p>\\\nWhile researching is important, do not forget an important aspect of investing—diversification. Diversifying your crypto portfolio is important as it helps mitigate the risks associated with the volatility of the crypto market.</p><p>\\\nAre you looking for the best platform that offers a variety of altcoins to help diversify your crypto portfolio? MEXC is your best deal.</p><p>\\\nIn addition to being one of the best and most reliable cryptocurrency exchanges, here are some of the benefits of using MEXC:</p><p>With over 3,000 tokens listed and new listings occurring almost daily, MEXC stands out from other cryptocurrency exchanges by offering the most cryptocurrency collections. Its efficient infrastructure and well-organized listing process allow it to list cryptocurrencies swiftly and early. Thus, investors can acquire lesser-known and emerging cryptocurrency tokens even before they are listed on other exchanges.</p><p>Liquidity is a key feature of the MEXC exchange platform. According to industry reports, , having a spot trading depth of $3.11 billion. It also has a futures depth of over $9.1 billion, surpassing the total of major exchanges. </p><p>\\\nWith its high liquidity and extremely low slippage, MEXC provides a favorable trading environment that allows traders to execute trades swiftly and efficiently. Little wonder, it is the crypto hub of more than 30 million users from over 170 countries.</p><h3><strong>Extremely Low Trading Fee</strong></h3><p>Another unique benefit of the MEXC crypto exchange is its extremely low trading fees. MEXC offers a 0.05% taker fee for spot trading and a 0.01% maker and 0.04% taker fee for futures trading. The result? Traders can maximize profits during altseasons.</p><p>\\\nDue to its exceptional services, MEXC has become the go-to crypto exchange for millions of users, achieving ground-breaking milestones.</p><p>\\\nTo illustrate with examples, here are two of MEXC’s achievements this past year:</p><ol><li><p><strong>Ranking among the top centralized exchanges (CEXs) for spot and derivative trading.</strong></p><p>According to the data obtained from Token Insight, MEXC ranked 6th and 5th among CEXs for spot trading and derivative trading in 2024. </p></li></ol><p>\\\nIn fact, its derivative trading volume increased by 132.35%, more than twice its 2023 volume. This is quite remarkable, highlighting MEXC’s hgh liquidity, wide user base, and diverse crypto offerings that cater to the needs of all kinds of traders.</p><p>\\\nThus, traders can easily buy cryptocurrencies, including memecoins, with minimal price slippage. MEXC also offers futures and margin trading options that allows traders to benefit from the price volatility of cryptocurrencies, including memecoins.</p><ol start=\"2\"><li><p><strong>Having the largest market share among CEXs.</strong></p><p>Market share refers to the proportion of trading activity a cryptocurrency exchange has compared to other exchanges. </p></li></ol><p>\\\nThis says a lot about MEXC’s trust and reputation. No wonder it is home to more than 30 million users from over 170 different countries.</p><h2><strong>How to Buy Altcoins on MEXC?</strong></h2><ul><li>: Visit the MEXC website and click the \"Sign Up\" button. Make sure to enable two-factor authentication to secure your account.</li><li>: You need to fund your account to purchase crypto on the MEXC platform. MEXC supports deposits in both cryptocurrencies and fiat currencies.</li><li><strong>Search for altcoins and place an order</strong>: To browse through a list of altcoins, visit the “Markets” section of the MEXC website. After selecting an altcoin, place an order.&nbsp;</li></ul><p>To maximize gains during an altseason, you need to know when to enter and leave the market. Technical analysis instruments like support and resistance levels and the relative strength index, can help determine entry and exit points.</p><p>\\\nSetting up stop-loss and take-profits levels is also a proactive step to minimizing loss.</p><p>Nothing beats being early. To refine your investment strategy, consider participating in token presales. Visiting the MEXC website for new listings also allows you to purchase new altcoins before they are listed on other exchanges.</p>","contentLength":8766,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hit The Snooze on Cache Keys and How It Boosts Web App Performance","url":"https://hackernoon.com/hit-the-snooze-on-cache-keys-and-how-it-boosts-web-app-performance?source=rss","date":1739293136,"author":"Alex Svetkin","guid":194,"unread":true,"content":"<p>Using an in-memory side cache to improve response times and alleviate the load on a database is one of the most common design patterns seen in web applications. This design scales well and has low setup and maintenance costs. A side cache can be added to an existing web application backend to speed up the loading of all types of data, from database records to larger chunks like complete JSON or HTML responses. By setting an expiration time, \"lazy caching” (or “lazy loading”) can be implemented, meeting the user's tolerance for stale data without the complexities of cache invalidation. Many excellent open-source solutions are available both on-premises and in the cloud, memcache and redis are considered the most popular. A caching scheme like this has been used in all the projects I have worked on.</p><p>\\\nAs system load increases, challenges inevitably emerge. Imagine your web application processing millions of requests daily. During peak traffic hours, users experience significant delays and occasional errors. To mitigate these issues, you expand your caching infrastructure by adding additional instances, expecting the increased cache size to resolve the bottlenecks. However, the performance issues persist, and your application continues to struggle under the load. This scenario, which I encountered repeatedly in the projects I worked on, necessitates a careful re-evaluation of our approach to caching under high demand.</p><p>Large technology companies often address such challenges with sophisticated software and intricate architectural changes. However, these solutions are not always accessible or cost-effective for smaller teams or organizations. Techniques such as implementing middleware proxies for request batching or adopting customized communication protocols may not align with your system's constraints. This article presents a practical method that my colleagues and I successfully employed to address similar challenges in large-scale projects.</p><h2>Latency spikes at top percentiles</h2><p>One of the frequent problems we encountered was high response times observed in top percentiles like p99, while mean and median times looked great. These high response times occurred due to the need to make database reads when cache keys were missing.</p><p>I created a simulation to represent a typical workload for a web application we used to have (see the Simulation section below for more details). This model application handles 100 requests per second for a single type of abstract key. The keys' popularity follows a Pareto distribution, with two-thirds of user requests concentrated among the first 1,000 keys out of a total of 1 million keys.</p><p>Mean cache read time is about 50 times higher than database read time. Cache expiration time is 20 minutes.</p><p>The p99 response times for these top 1000 keys are extremely high (top left chart), while the mean and median response times are within an acceptable threshold. The long tail of less popular keys isn’t considered here because their hit ratio is significantly lower, thus making caching much less efficient for them beforehand.</p><p>\\\nBut are high values at 99th percentile for popular keys that bad? That means that just about 1% of key reads are slow. Though it depends on your application and its usage patterns, this is generally unfavourable. Think about the following real-world scenarios:</p><ul><li>A single user's request fetches hundreds of keys — a typical case for social and news feeds etc. Though only 1 out of 100 keys are slow but almost every user request is slow because of that;</li><li>Hundreds of users request the same key at the same moment — a common thing pattern for any popular site. When this key expires, all these requests go straight to the database, multiplying its load, slowing down the whole backend.</li></ul><p>I want to emphasize that this happens not to “some requests” but to the most popular ones, which represent the core of your users’ demand.</p><p>Setting keys expiration time to infinity could solve the problem with peaking loading times. Unfortunately, this also denies “lazy caching” and demands cache invalidation mechanisms.  Is it possible to eliminate the issue of key expiration while still providing data that is acceptably up to date?</p><h2>Dynamically extending keys expiration time</h2><p>The desire to serve fresh data while maintaining low response times and database load is inherently contradictory. The ideal solution would be to know in advance if a retrieved key from the cache is about to expire and update it if necessary, preferably in the background. Here is an example solution written in pseudo-python code:</p><pre><code>cache_response = cache.get(key)\nif cache_response is not None: \n  if random() &lt; α:\n    run async: # this block will run in background and not delay the response\n      db_response = dabase.get(key)\n      if db_response is not None:\n          # note cas_token, see explanation for CAS below\n          cache.set(key, db_response.value, cache_response.cas_token) \n\n  # returning value to the user\n  return cache_response.value \n</code></pre><p>\\\nWe read a key from cache and, if successful,&nbsp;with small probability set its value again,&nbsp;also extending the expiration time. This involves reading the key from the database to check for updates.</p><p>To avoid race conditions, CAS or Check and Set mode must be used. CAS ensures that the cache update only happens if the data hasn't been modified by another process since it was last read, maintaining data consistency.</p><p>The key set should be done asynchronously to avoid delaying user responses. Even if it isn't possible, it may be still beneficial to update the key blocking the user.</p><p>Choosing the optimal probability  depends on your traffic pattern and is generally recommended to be between 1% and 10%. Higher values increase database load without significantly affecting popular keys.</p><p>\\\nIn systems where keys are not frequently updated, expiration times are longer, and request rates are high, an additional strategy can be implemented. Keys may be updated with probability α, but only if their remaining expiration time is below .</p><p>This technique requires the ability to read the expiration time. Redis provides the  command for this purpose, while memcache does not. This can be addressed by storing the expiration time alongside the value, for example, packed in JSON.</p><p>Modifying caching behavior of your system in production is risky, to say the least, so it's safer to apply changes gradually. However, due to the unpredictable nature of the incoming traffic, distinguishing small improvements from noise requires complex data analysis. Development or staging environments proved to be not much better in my cases as they had lower traffic.</p><p>To tackle this, I used discrete simulation tools for ad-hoc simulations. This approach allowed me to safely test any system behavior I wanted to research much faster than running such experiments in a development environment.</p><p>While I was composing this article, I compiled numerous code snippets utilized during these experiments into a single&nbsp;tool and made it available through a github repository: <a href=\"https://github.com/whisk/cachestudy\">https://github.com/whisk/cachestudy</a>.</p><p>The expiration time extension technique I described in this article shows that improving web application performance doesn’t always require expensive tools or complex changes. By addressing common caching challenges developers can significantly boost efficiency and handle high traffic with simple, cost-effective solutions.</p><p>\\\nHowever, these improvements must be carefully tested in production environments to ensure they work as intended and don’t create new problems. Simulations and pre-production environments often lack the complexity and scale of real-world traffic, and only by testing under actual conditions can you ensure your optimizations provide tangible gains without introducing new issues.</p><p>Cover image generated by DALL·E.</p>","contentLength":7837,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"New Space Economy: Trends of Advanced Development","url":"https://hackernoon.com/new-space-economy-trends-of-advanced-development?source=rss","date":1739292716,"author":"NFT Bro","guid":193,"unread":true,"content":"<p>\\\nIn continuation of the topic raised in the last article, I decided to conduct a study of the space industry development based on the concept of “new space economy”.</p><p>\\\n==The new space economy is a global trend based on a number of technological innovations and a certain business model. According to <a href=\"https://www.morganstanley.com/Themes/global-space-economy\">Morgan Stanley</a>, this industry can already be valued at $350 billion and could reach $1 trillion by 2040. This opens up new opportunities for the automotive, tourism, energy, telecommunications, transportation, and other important industries to increase their profitability or improve the structure of work on Earth or in space.==</p><h3>The main prerequisites for my research were:</h3><ol><li>Strong growth of companies and new technological solutions in the space industry;</li><li>Decreasing cost of transportation to Earth orbit;</li><li>Growth in the number of spacecraft;</li><li>The explosive growth of the space economy and its interrelationships with Earth-based industry and economy;</li><li>Application of industrial and IT innovations to the space industry;</li><li>Unpredictable revolutionary changes in economic models in the space-Earth nexus (black swans).</li></ol><h3>I have also identified the most promising technologies for the “new space economy” and these are:</h3><ol><li>Spacecraft mass production;</li><li>Serial production of ultra-light rockets for constellation replenishment and low-orbit launches;</li><li>Heavy and super-heavy rockets for launching payloads into high orbits and launches to the Moon;</li><li>High-power autonomous power supply systems (up to 500 kW);</li><li>Laser communication and navigation systems for long-range communications;</li><li>Autonomous satellites and rovers;</li><li>New types of engines, including those that do not require reactive mass or significantly reduce its consumption, allow for constant operation both in low orbits and in space;</li><li>New materials for various systems (protective, heat dissipating, etc);</li><li>Electronic component base (including radiation-resistant) increasing computing performance in space (spacecraft, rovers, stations, and in the future on orbital data centers);</li><li>New types of energy-efficient sensors and systems based on them;</li><li>Technologies of autonomous production (robotization, additive technologies, AI, new materials processing technologies, etc.).</li></ol><p>\\\nBased on this, I conclude the main trends of advanced development.</p><h2>Main trends of advanced development for SpaceTech</h2><ul><li><strong>Multifunctional autonomous heavy platforms and satellites with universal (typified) connectors and data exchange protocols.</strong> Unified standards for all satellites and bases for compatibility of various assemblies and designs. Development of the principles of modular construction of satellites (spacecraft) and stations (automated and manned) for space and satellite surfaces. This will provide the unification of technical solutions and the possibility of building complex technical systems without being tied to a country or a manufacturing company.</li><li><strong>A unified network of communication, navigation, and space traffic control based on AI.</strong> Creation of a unified system of space traffic dispatching in the Earth-Moon space with integration of all participants of space exploration programs. ExtraNet is a unified network of data collection, storage, and transmission in space. Extraterritorial principle of access to information, acceleration of data processing for space applications. Verified settlement system using blockchain technologies.</li><li><strong>==Extraterritoriality of space law, new regulations, and legislation.==</strong> ==Freedom of data exchange and settlement in space. Development of the ideology of humanity as a single nation. New principles of governance and cohabitation.==</li><li><strong>Creation of a new space economy based on goods and services produced in space and their consumption in space.</strong> Multiple growth of interaction of Earth industry and economy with space industry and economy.</li><li><strong>New energy-efficient technologies and solutions adaptable for Earth applications.</strong> Biotechnology, new pharmaceuticals, biomaterials printing, photonic processors, superconductivity, magnetic levitation, automated factories and robotic mining systems, robotic shipyards using additive technologies (3D printing of structures and spacecraft in microgravity), autonomous rovers and harvesters.</li><li><strong>Achieving self-sustainability of space systems.</strong> Extraction of minerals and necessary resources for life support systems. Waste recycling technologies and self-sustaining closed ecosystems of bases and stations.</li><li><strong>Creation of new logistic chains.</strong> I mean ==Low orbits / high orbits / geostationary orbits / Lagrange points / Luna using autonomous satellites (tugs)== with long operating times to reduce the cost of transportation. Using AI, creating a network of automatic stations for dispatching and traffic control to reduce accidents (avoiding the <a href=\"https://solar-mems.com/blog-news/the-kessler-effect-the-potential-danger-of-the-domino-effect-for-space-debris/\">Kessler effect</a>).</li><li> Protection from radiation and space radiation, new alloys (produced in microgravity). Discovery of new chemical elements and compounds and creation of materials with their application.</li><li><strong>International Space University.</strong> Working with the “Big Challenges,” embodiment of the&nbsp;<a href=\"https://www.jstor.org/stable/26495755\">idea of “Mega Science”</a>&nbsp;by taking science and research beyond jurisdictions, hosting on a platform with hosting space infrastructure allows for development trends on interdisciplinarity, openness, and digitalization.  The use of an extraterritorial payment system will make it possible to obtain funding for research outside national institutions. Creation of new training systems for professionals and scientists for the industry through continuously updated digital training programs and practice with real cases.</li><li><strong>Synergetic revolutionary change of business models of the Earth economy.</strong> This will happen with the participation of the space economy. For example, industrial mining of platinum on asteroids will create an economically sound industry of hydrogen transport and hydrogen fuel cells for independent energy supply, which will remove electric transport and wind and solar energy. Another example is hydrocarbon extraction on the moons of Jupiter and Saturn, which will increase the Earth's economy by 1000 times.</li><li>==, we will see the expansion of mankind in the solar system and the expansion of the zone of life.==</li></ul><p>\\\nAll this will allow us to create completely new technical systems and production directions, as well as significantly expand the capabilities of existing industries.</p><h2>Possible directions of development for Space Tech</h2><p>\\\nLet's consider possible directions of development.</p><h3>Creation of an infrastructure for access to energy supply anywhere in the solar system</h3><p>For this project, all existing energy generation systems will be used, which will complement each other and give impetus to the technological development of autonomous energy supply systems (solar panels, nuclear technologies, energy storage systems). New solutions for wireless energy transmission in a vacuum.</p><h3>Automated transportation networks</h3><p>This includes Orbital and space tugs using new types of plasma and ion engines. Development and application of new types of fuels. Automated refueling, repair, and upgrade stations (GateWay's). Dispatching of movement in near-Earth, near-lunar, and outer space using AI on the basis of orbital and space data centers. New chains and principles of logistics in high Earth orbit, near-lunar space, on the Moon and in the Solar System (Separation of transportation services by orbits and Earth-Moon paths).</p><p>Laser communication systems and high-precision positioning systems. Positioning stations in space in 3-dimensional coordinate system (space and lunar navigation). Remote control of UAV drones by operators from Earth for complex tasks.</p><p>Automated stations with customizable production cycle and standardized modules for equipment placement. Incorporating manufacturing facilities into new supply chains. 3D printing of space structures and spacecraft in microgravity using automated drones. Alloys and materials are produced only in microgravity. Technologies for creating self-sustaining ecosystems (waste management, water and air purification, food and medicine production). Cultivation of extremely pure and harmonized crystals.</p><p>Automated geological probes/automated and robotic mining systems. Base station with a power core, data center, and long-distance communication node+robotic drones for mining and primary processing of resources. Typical modules for automated and manned stations in space and on the surface of the Moon will also develop. Then, on the surfaces of satellites and asteroids. Rapid development of all planets and asteroids, with the construction of international settlements.</p><p>Creation of digital automated diagnostic complexes on the basis of historical datasets on changes in human condition in space, diagnostic techniques, and preventive methods with the application of AI. Development of treatment programs in microgravity conditions. Growing biomaterials in microgravity/bioprinting, operations in microgravity (automated robotic operating complexes, remote control of medical complexes).</p><h3>Unified network of data collection, storage, and transmission outside the Earth</h3><p>This includes Orbital data centers, data centers on the Moon, and space stations. Radiation-resistant electronic components. Photonic processors.</p><p>Recent events show that it is time for mankind to go out into the solar system and master it in full. Even already existing technologies are sufficient for the united expansion of mankind into space. Development of asteroids can significantly improve life on Earth (for example, obtaining platinum at the price of aluminum will revolutionize the entire transportation industry, replacing gasoline and diesel with hydrogen) and increase the size of the economy by thousands of times. Establishing full-fledged settlements on other planets and satellites will expand the range of human habitation. The creation of new materials, the development of medicine and pharmaceutics, and the development of new technologies in space will allow us to go further into other star systems.</p>","contentLength":9960,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EU Pledges $200 Billion in AI Spending in Bid To Catch Up With US, China","url":"https://news.slashdot.org/story/25/02/11/1617259/eu-pledges-200-billion-in-ai-spending-in-bid-to-catch-up-with-us-china?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739292600,"author":"msmash","guid":285,"unread":true,"content":"The European Union pledged to mobilize 200 billion euros ($206.15 billion) to invest in AI as the bloc seeks to catch up with the U.S. and China in the race to train the most complex models. From a report: European Commission President Ursula von der Leyen said that the bloc wants to supercharge its ability to compete with the U.S. and China in AI. The plan -- dubbed InvestAI -- includes a new 20 billion-euro fund for so-called AI gigafactories, facilities that rely on powerful chips to train the most complex AI models. \"We want Europe to be one of the leading AI continents, and this means embracing a life where AI is everywhere,\" von der Leyen said at the AI Action Summit in Paris. \n\nThe announcement underscores efforts from the EU to position itself as a key player in the AI race. The bloc has been lagging behind the U.S. and China since OpenAI's 2022 release of ChatGPT ushered in a spending bonanza. [...] The EU is aiming to establish gigafactories to train the most complex and large AI models. Those facilities will be equipped with roughly 100,000 last-generation AI chips, around four times more than the number installed in the AI factories being set up right now.","contentLength":1186,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TapSwap To Be Listed On Bitget: A Gateway To Long-Term Success","url":"https://hackernoon.com/tapswap-to-be-listed-on-bitget-a-gateway-to-long-term-success?source=rss","date":1739292325,"author":"BTCWire","guid":192,"unread":true,"content":"<p>Mark Your Calendars: February 14, 2025</p><p>We’re thrilled to announce that TapSwap, the world’s first Web3 skill-gaming platform, is taking a giant leap forward with its listing on Bitget on February 14, 2025. </p><p>\\\nThis milestone marks an exciting new chapter in our journey, reinforcing our commitment to building a sustainable and rewarding gaming ecosystem for millions of players worldwide.</p><h2>TapSwap: Where Skill Meets Crypto</h2><p>Unlike traditional play-to-earn models that rely on luck or monotonous grinding, TapSwap is all about . Players are rewarded for their mastery and competitive edge rather than chance, creating a truly meritocratic environment where skill determines success.</p><p>\\\nWith a transparent blockchain-powered system, we ensure fair play, real earning opportunities, and a thriving economy centred around our native TAPS token.</p><p>\\\nWith over 72 million total users, 3 million daily active users (DAU), and 10 million weekly active users (WAU), TapSwap has quickly grown into one of the most active Web3 gaming communities. </p><p>\\\nWhether you're a casual gamer or an esports competitor, TapSwap offers a platform where you can compete, earn, and engage in a decentralized gaming experience like never before.</p><h2>The Power of the TAPS Token</h2><p>At the core of TapSwap’s ecosystem is the TAPS token, designed to power the platform’s economy and provide multiple avenues for user engagement, including:</p><ul><li>Tournament Participation: Enter skill-based tournaments with TAPS and compete for substantial rewards.</li><li>Fight2Earn: A high-stakes mode where players battle for TAPS rewards based purely on skill.</li><li>Staking &amp; Passive Income: Users can stake TAPS to earn rewards while contributing to the ecosystem’s stability.</li><li>Governance: Token holders influence platform decisions, shaping the future of TapSwap.</li><li>In-Game Purchases &amp; Premium Access: Enhance your gaming experience with exclusive skins, avatars, and premium accounts.</li></ul><h2>Why the Bitget Listing Matters</h2><p>Our listing on Bitget, a leading cryptocurrency exchange, is a major step toward long-term success for TapSwap and its growing community. This listing:</p><ul><li>Boosts TAPS liquidity and accessibility</li><li>Opens doors for new investors and gamers</li><li>Strengthens TapSwap’s position in the Web3 gaming market</li><li>Creates more opportunities for the TapSwap community to grow and thrive</li></ul><p>\\\nBy listing on Bitget, we’re not just increasing the reach of the TAPS token—we’re creating a gateway for millions of users to join the TapSwap movement and benefit from a truly skill-based gaming economy.&nbsp;</p><h2>GATE OPPORTUNITY: Don’t Miss Out</h2><p>With the Bitget listing right around the corner, now is the perfect time to get involved in TapSwap’s ecosystem. Whether you’re a gamer, investor, or blockchain enthusiast, this is your chance to be part of a revolutionary Web3 gaming platform.</p><p>\\\n🚨 BIG NEWS FOR THE TAPSWAP COMMUNITY! 🚨</p><p>\\\nAll TapSwap community members have just received 10 tickets in the TapSwap mini-app! 🎟️ These tickets are your FREE entry to the BIG GAME happening at the launch of our Web3 skill gaming platform! 🕹️🔥</p><p>\\\n🏆 $1 MILLION PRIZE POOL—for the winners of this epic competition! 💰💎</p><p>Didn’t participate in the TapSwap app? No worries—you’ll still have the chance to buy tickets and join the game!</p><p>\\\nThe future of skill-based gaming is here, and we’re just getting started. TapSwap is one of the first tap-to-earn projects that is transforming into a full-fledged gaming platform. Invest, play, and win with TapSwap!</p><p>:::tip\nThis story was distributed as a release by Btcwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":3608,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CISA election security officials placed on leave, DHS confirms","url":"https://techcrunch.com/2025/02/11/cisa-election-security-officials-placed-on-leave-report/","date":1739292000,"author":"Carly Page","guid":137,"unread":true,"content":"<p>A senior DHS official confirmed CISA employees involved in election security were put on leave.</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":158,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Navigating Digital Classrooms As Educators—Are We Ready to Adapt?","url":"https://hackernoon.com/navigating-digital-classrooms-as-educatorsare-we-ready-to-adapt?source=rss","date":1739291777,"author":"Revising","guid":191,"unread":true,"content":"<li><p>Celik, I., Dindar, M., Muukkonen, H., Järvelä, S. (2022): The Promises and Challenges of Artificial Intelligence for Teachers: a Systematic Review of Research. TechTrends. doi:10.1007/s11528-022-00715-y</p></li><li><p>Ley, T., Tammets, K., Pishtari, G., Chejara, P., Kasepalu, R., Khalil, M., Saar, M., Tuvi, I., Väljataga, T., Wasson, B. (2023): Towards a partnership of teachers and intelligent learning technology: A systematic literature review of model‐based learning analytics. Journal of Computer Assisted Learning. doi:10.1111/jcal.12844</p></li><li><p>Pishtari, G., Ley, T., Khalil, M., Kasepalu, R., Tuvi, I. (2023): Model-Based Learning Analytics for a Partnership of Teachers and Intelligent Systems: A Bibliometric Systematic Review. Education Sciences. doi:10.3390/educsci13050498</p></li><li><p>Alt, D., Nirit, R. (2018): Lifelong Citizenship. Lifelong Learning as a Lever for Moral and Democratic Values. Moral Development and Citizenship Education, vol. 13. Brill/Sense, Leiden, the Netherlands. doi:10.1163/9789463512398. 978-94-6351- 239-8</p></li><li><p>Alt, D., Naamati-Schneider, L., Weishut, D.J. (2023): Competency-based learning and formative assessment feedback as precursors of college students’ soft skills acquisition. Studies in Higher Education. doi:10.1080/03075079.2023.2217203</p></li><li><p>Ghaicha, A. (2016): Theoretical Framework for Educational Assessment: A Synoptic Review. Journal of Education and Practice 7, 212–231</p></li><li><p>Rust, C. (2002): Purposes and Principles of Assessment. Learning and Teaching Briefing Papers Series</p></li><li><p>Curry, R.A., Gonzalez-DeJesus, N.T. (2010): A Literature Review of Assessment. Journal of Diagnostic Medical Sonography. doi:10.1177/8756479310361374</p></li><li><p>Machin, L. (2016): A complete guide to the level 5 diploma in education and training. Further Education. Critical Publishing Ltd, Northwich. 978-1910391785</p></li><li><p>Schildkamp, K., van der Kleij, F.M., Heitink, M.C., Kippers, W.B., Veldkamp, B.P. (2020): Formative assessment: A systematic review of critical teacher prerequisites for classroom practice. International Journal of Educational Research. doi:10.1016/j.ijer.2020.101602</p></li><li><p>Spatioti, A.G., Kazanidis, I., Pange, J. (2022): A Comparative Study of the ADDIE Instructional Design Model in Distance Education. Information. doi:10.3390/info13090402</p></li><li><p>Frerejean, J., van Merriënboer, J.J., Kirschner, P.A., Roex, A., Aertgeerts, B., Marcellis, M. (2019): Designing instruction for complex learning: 4C/ID in higher education. Euro J of Education. doi:10.1111/ejed.12363</p></li><li><p>Mislevy, R.J., Behrens, J.T., Dicerbo, K.E., Levy, R. (eds.) (2012): Design and Discovery in Educational Assessment: Evidence-Centered Design, Psychometrics, and Educational Data Mining 4(1). doi:10.5281/zenodo.3554641</p></li><li><p>Gnadlinger, F., Selmanagić, A., Simbeck, K., Kriglstein, S. (2023): Adapting Is Difficult! Introducing a Generic Adaptive Learning Framework for Learner Modeling and Task Recommendation Based on Dynamic Bayesian Networks. In: Jovanovic, J., Chounta, I.-A., Uhomoibhi, J., McLaren, B. (eds.) Proceedings of the 15th International Conference on Computer Supported Education. 15th International Conference on Computer Supported Education, Prague, Czech Republic, 21.04.2023 - 23.04.2023, pp. 272–280. SCITEPRESS. doi:10.5220/0011964700003470</p></li><li><p>Almond, R.G., Mislevy, R.J., Steinberg, L.S., Yan, D., Williamson, D.M. (2015): Bayesian Networks in Educational Assessment. Statistics for Social and Behavioral Sciences. Springer, New York, NY. doi:10.1007/978-1- 4939-2125-6. 9781493921256</p></li><li><p>Shute, V.J., Rahimi, S., Smith, G., Ke, F., Almond, R., Dai, C.-P., Kuba, R., Liu, Z., Yang, X., Sun, C. (2021): Maximizing learning without sacrificing the fun: Stealth assessment, adaptivity and learning supports in educational games. J Comput Assist Learn. doi:10.1111/jcal.12473</p></li><li><p>Hughes, J. (2022): Deskilling of Teaching and the Case for Intelligent Tutoring Systems. J. Eth. Emerg. Tech. doi:10.55613/jeet.v31i2.90</p></li><li><p>Vanbecelaere, S., van den Berghe, K., Cornillie, F., Sasanguie, D., Reynvoet, B., Depaepe, F. (2020): The effectiveness of adaptive versus non‐adaptive learning with digital educational games. Journal of Computer Assisted Learning. doi:10.1111/jcal.12416</p></li><li><p>Talaghzi, J., Bennane, A., Himmi, M.M., Bellafkih, M., Benomar, A. (2020): Online Adaptive Learning. In: Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications. SITA'20: Theories and Applications, Rabat Morocco, 23 09 2020 24 09 2020, pp. 1–6. ACM, New York, NY, USA. doi:10.1145/3419604.3419759</p></li><li><p>Gao, Y. (2023): The Potential of Adaptive Learning Systems to Enhance Learning Outcomes: A Meta-Analysis. doi:10.7939/r3-a6xdm403</p></li><li><p>Manouselis, N., Drachsler, H., Vuorikari, R., Hummel, H., Koper, R. (2011): Recommender Systems in Technology Enhanced Learning. In: Ricci, F. (ed.) Recommender systems handbook, pp. 387–415. Springer, New York. doi:10.1007/978-0-387-85820-3_12</p></li><li><p>Ricci, F., Rokach, L., Shapira, B. (eds.) (2015): Recommender Systems Handbook. Springer, New York. doi:10.1007/978-1-4899- 7637-6. 978-1-4899-7636-9</p></li><li><p>Ramadhan, A., Warnars, H.L.H.S., Razak, F.H.A. (2023): Combining intelligent tutoring systems and gamification: a systematic literature review. Educ Inf Technol. doi:10.1007/s10639-023-12092-x</p></li><li><p>Kurni, M. (2023): A Beginner's Guide to Introduce Artificial Intelligence in Teaching and Learning, 1st edn. Springer International Publishing; Springer, Cham. 978-3-031-32653-0</p></li><li><p>Abdelbaset R. Almasri, Adel Ahmed, Naser Al-Masri, Yousef S. Abu Sultan, Ahmed Y. Mahmoud, Ihab Zaqout, Alaa N. Akkila, Samy S. Abu-Naser (2019): Intelligent Tutoring Systems Survey for the Period 2000- 2018. International Journal of Academic Engineering Research (IJAER) vol. 3, 21-37</p></li><li><p>Woolf, B.P. (2010): Building Intelligent Interactive Tutors. Elsevier Science. 978-0-08- 092004-7</p></li><li><p>Dermeval, D., Paiva, R., Bittencourt, I.I., Vassileva, J., Borges, D. (2018): Authoring Tools for Designing Intelligent Tutoring Systems: a Systematic Review of the Literature. Int J Artif Intell Educ. doi:10.1007/s40593- 017-0157-9</p></li><li><p>Verbert, K., Duval, E., Klerkx, J., Govaerts, S., Santos, J.L. (2013): Learning Analytics Dashboard Applications. American Behavioral Scientist. doi:10.1177/0002764213479363</p></li>","contentLength":6141,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeFi 2.0: Cables Finance Is Building an Integrated DEX With LST A Perpetual Futures Trading For FX R","url":"https://hackernoon.com/defi-20-cables-finance-is-building-an-integrated-dex-with-lst-a-perpetual-futures-trading-for-fx-r?source=rss","date":1739291743,"author":"BTCWire","guid":190,"unread":true,"content":"<p>DeFi has grown, but trading still feels like a mess. Markets have expanded into real-world assets (RWAs), perpetual futures, and FX, but the actual experience of trading across these assets is full of friction.</p><p>\\\nTraders deal with fragmented liquidity, collateral stuck in staking contracts, and a system that still revolves around USD stablecoins.</p><p>\\\n is fixing this by launching an Integrated DEX with LST &amp; Perp Futures for FX RWAs. By combining liquid staking RWAs with a Perpetual Futures DEX, Cables enables assets like cEUR, cJPY, and cXAU to function as both collateral and tradable instruments, eliminating the inefficiencies of fragmented liquidity.</p><p>\\\nInstead of forcing participants to move liquidity across different protocols, Cables connects yield, collateral, and trade execution in a single system—powering the Cables Liquidity Flywheel.</p><p>\\\nThis self-reinforcing cycle allows the Cables Community to deposit anything, earn yield on anything, and trade or leverage it without friction.</p><p>\\\nCables recently  and , outlining how it will seamlessly integrate RWAs into DeFi 2.0. With a focus on building for the Cables Community—not just users—this next evolution of DeFi puts accessibility, liquidity, and global adoption at the forefront.</p><h3>DeFi Still Feels Like Using a Flip Phone in 2025</h3><p>For all its advancements, DeFi still feels outdated. Traders looking to hedge non-USD currencies, earn yield on real-world assets, or trade multiple markets often end up bouncing between different platforms, waiting on bridges, and converting back to USD just to execute trades.</p><p>\\\nLiquidity is scattered across different chains, making it harder to enter and exit positions efficiently. Assets that should be usable in trading are locked in staking contracts, leaving traders to choose between earning passive yield or keeping capital available.</p><p>\\\nAnd for those looking to trade outside the USD-dominated system, choices are limited—most DeFi pairs still revolve around USDT or USDC, forcing FX traders into unnecessary conversions.</p><p>\\\nDeFi shouldn’t just be about adding more assets. It should be about making them usable in real markets. That’s where Cables’ launch of its Integrated LST &amp; Perpetual Futures for FX RWAs in one DEX will dominate and show the world what DeFi 2.0 truly means.</p><h3>Cables’ Integrated LST &amp; Perpetual Futures for FX RWAs in One DEX</h3><p>Cables Finance is solving this by making liquid staking RWAs a core piece of trading infrastructure. With liquid staking, the Cables Community doesn’t have to choose between earning yield and accessing deep, liquid markets. Assets like cEUR, cJPY, and cXAU remain liquid, earning yield while serving as active collateral on the Cables Perp DEX.</p><p>\\\nA trader looking to hedge euro exposure can hold cEUR, collect yield, and use it for leveraged positions at the same time. A gold-backed stable asset like cXAU provides access to a decentralized gold market while acting as collateral.</p><p>\\\nInstead of unstaking funds or swapping between isolated liquidity pools, the Cables Community can trade, hedge, and earn in one place.</p><p>This approach removes unnecessary steps from DeFi trading. Instead of shifting liquidity between staking and active markets, capital can move freely within a single system.</p><h3>Cables Finance: The Trading Desk DeFi Actually Needs</h3><p>The future of DeFi isn’t just about adding assets—it’s about making them work for traders. Liquid staking RWAs allow traders to keep assets active while earning yield, removing the trade-offs that exist today.</p><p>\\\nCables Finance combines deep liquidity with perpetual futures, creating a trading system where RWAs aren’t just passive holdings—they’re part of an active, high-volume market. Instead of treating RWAs as an afterthought, Cables puts them at the core of DeFi 2.0 trading.</p><p>\\\nDeFi has spent years making assets tradable. Now, Cables Finance is making trading better—with a Liquidity Flywheel that connects deposit, yield, and leverage in one system.</p><p>DeFi 2.0 is here. The Cables Community is building it.</p><p>:::tip\nThis story was distributed as a release by Btcwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":4162,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Climb the Ranks: 3 Actionable Tips to Become a Top Writer","url":"https://hackernoon.com/climb-the-ranks-3-actionable-tips-to-become-a-top-writer?source=rss","date":1739290503,"author":"Editing Protocol","guid":189,"unread":true,"content":"<p>\\\nAre you ready to get the recognition you deserve for your writing? Landing a spot in —the place where we acknowledge and celebrate the top writers in each — can boost your reputation and connect you with a thriving tech audience. Here are three proven strategies to help you reach the top.</p><p>If you’ve written an article but haven’t published it because it’s not perfect, you’re holding yourself back. The best way to gain experience and get your name out there is by writing and publishing consistently.</p><p>\\\nSet attainable goals, like publishing once a week or once every two weeks. Writing regularly is crucial for improving your skills as a writer and for becoming a  at HackerNoon.</p><p>\\\n<strong>==Why is consistency important?==</strong></p><p>Our  ranking looks at the most recent 100 stories per category and tracks how many stories each writer has published. For example, if you’ve written 10 stories out of those 100, you may secure a top spot, depending on other writers’ contributions. The rankings are updated daily, so it’s a great way to stay visible and relevant in your favorite category. Learn more about HackerNoon’s Top Writers Rankings .</p><p>\\\nSo, if you want to be a top writer in the , focus on creating a lot of stories about programming. If you’re feeling stuck or running low on inspiration, check out the  to see what other great HackerNoon writers are publishing.</p><p>\\\nAnd if programming isn’t your thing, don’t worry! We’ve got 21 other  for you to explore and dive into.</p><p>:::tip\nLooking for your next article idea? Why not try writing about the latest tech news? Use this <a href=\"https://app.hackernoon.com/new?template=techcompany-news-in-context\">template</a> as a guideline!</p><h2>2. Write About What You’re Passionate About (A.K.A., Build Up a Good Reputation)</h2><p>Writing about topics you’re passionate about can transform your work. Readers sense when you truly care, and that energy helps build your reputation. Whether it’s AI, gaming, or blockchain, let your enthusiasm shine.</p><p>\\\nOn the flip side, if you write about something you’re not interested in—just for the sake of views—your article may come across as cold and lifeless. This can hurt your reputation as a writer.</p><p>\\\nThat’s not to say you should never write for views, but make sure the topic interests you personally. If you’re struggling to find ideas, check out the . You can organize it by most-engaged, most-recent and most-commented stories of the week to uncover what the HackerNoon community is buzzing about, identify trends and write articles that resonate with readers.</p><p>:::tip\nIf you’re extremely passionate about a topic and think everyone should know more about it, use this <a href=\"https://app.hackernoon.com/new?template=everyone-should-know-about-it\">template</a> to get the word out!</p><p>If you want to write more but often struggle with what to write about next, here’s a secret technique: think less about multiple story ideas and more about  you can evolve over time. A series is a great way to stay consistent while exploring a topic in-depth.</p><p>\\\nFor example, if you’re passionate about crypto, why not start a series where you review a different cryptocurrency each week? The content changes, but the format remains the same. HackerNoon writer  did exactly that with his  series, which earned him thousands of views.</p><p>\\\nOr, if you’re into programming, create a series where you teach readers how to fix a specific problem/bug every week.  has done this successfully with his Code Smells series.</p><p>\\\n\\\n<strong>==Want to know what works best in your category?==</strong></p><p>\\\nAnd remember: this approach isn’t limited to gaming. Whether you’re writing about , , or , the sky’s the limit!</p><p>:::tip\nIf writing a guide sounds like a good series idea, use this <a href=\"https://app.hackernoon.com/new?template=how-to-write-a-guide-on-hackernoon\">template</a> to get started.</p><h2>Don’t Forget to Check Out Our Writing Contests!</h2><p>Don’t miss your chance to win big! HackerNoon’s writing contests are the perfect way to share your expertise and score some serious rewards.</p><p>:::tip\nLooking for inspiration? We’ve got you covered with these handy templates:</p><p>\\\n\\\nThat’s it for this week.</p>","contentLength":3901,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meta Starts Eliminating Jobs in Shift To Find AI Talent","url":"https://tech.slashdot.org/story/25/02/11/1612249/meta-starts-eliminating-jobs-in-shift-to-find-ai-talent?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739290320,"author":"msmash","guid":284,"unread":true,"content":"Meta began notifying staff of job cuts on Monday, kick-starting a process that will terminate thousands of people as the company cracks down on \"low-performers\" and scours for new talent to dominate the AI race. From a report: Meta workers who were let go were notified via email, and the company is offering US-based employees severance packages that include 16 weeks of salary, in addition two weeks for each year of service, according to people familiar with the matter, who asked not to be named because the details weren't public. Employees whose review merited a bonus will still get one, and staff will still receive stock awards as part of the upcoming vesting cycle later this month, the people said. \n\nChief Executive Officer Mark Zuckerberg told employees that Meta would cut 5% of its workforce -- as many 3,600 people -- with a focus on staff who \"aren't meeting expectations,\" Bloomberg News first reported in mid-January. Affected US-based employees would be notified on Feb. 10, while international employees could learn later, Zuckerberg said last month. In a separate message to managers, the Facebook co-founder said the cuts would create headcount for the company to hire the \"strongest talent.\"","contentLength":1215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: AI Coding Tools Are Still in the RD Stage (2/11/2025)","url":"https://hackernoon.com/2-11-2025-newsletter?source=rss","date":1739289913,"author":"Noonification","guid":188,"unread":true,"content":"<p>🪐 What’s happening in tech today, February 11, 2025?</p><p>By <a href=\"https://hackernoon.com/u/andrei9735\">@andrei9735</a> [ 7 Min read ] In this post well continue working on link prediction with the Twitch dataset. <a href=\"https://hackernoon.com/before-ai-predicts-your-next-friend-it-needs-to-do-this-first\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/@javar97\">@@javar97</a> [ 7 Min read ] According to Stack Overflows 2024 survey, 76% of developers are using or planning to use AI tools. <a href=\"https://hackernoon.com/ai-coding-tools-are-still-in-the-randd-stage\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/edwinliavaa\">@edwinliavaa</a> [ 3 Min read ] While Bitcoins design brilliantly enables decentralization, human nature consistently pulls us toward centralization. <a href=\"https://hackernoon.com/bitcoin-is-eerily-resembling-the-financial-system-it-was-meant-to-replace\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/abhiyanampally_kob9nse8\">@abhiyanampally_kob9nse8</a> [ 40 Min read ] Dive into the comparitive analysis between logarithmic and floating-point arithmetic in neural nets using the commonly used MNIST dataset. <a href=\"https://hackernoon.com/deep-learning-runs-on-floating-point-math-what-if-thats-a-mistake\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/heinhtetkyaw\">@heinhtetkyaw</a> [ 5 Min read ] Myanmar Spring Revolution is empowered by Blockchain as both care about democracy, Federalism, civil liberties and decentralization. <a href=\"https://hackernoon.com/how-blockchain-became-myanmars-secret-weapon-against-a-totalitarian-regime\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>","contentLength":1085,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chalkboards & Code—Remixing the Digital Classroom","url":"https://hackernoon.com/chalkboards-and-coderemixing-the-digital-classroom?source=rss","date":1739289779,"author":"Revising","guid":187,"unread":true,"content":"<p>(1) Florian Gnadlinger, Faculty of Computer Science, Communication, and Economics, University of Applied Sciences Berlin, Germany;</p><p>(2) Simone Kriglstein, Faculty of Informatics, Masaryk University, Czech Republic.</p><p>\\\n: This contribution draws attention to implications connected with meta-architectural design decisions for intelligent tutoring systems in the context of formative assessments. As a first result of addressing this issue, this contribution presents a meta-architectural system design that includes the role of educators.</p><p>According to an ongoing systematic literature review and similar reviews that have already been conducted [1–3], we see evidence that intelligent tutoring systems are developed from a conceptual perspective in a black-box manner for the actual participants of educational assessment scenarios.</p><p>\\\nThis emphasizes the necessity to examine system designs, employed algorithms, and the conceptual implementation of pedagogical-psychological models in intelligent tutoring systems to enhance explainability and transparency for all stakeholders. A first step to do so is to reflect on intelligent tutoring systems beyond their current borders and to question:</p><p>\\\n<em>RQ1: How can we incorporate the role of educators into meta-architectural designs of intelligent tutoring systems to foster their explainability and transparency?</em></p><p>Competency-based learning (or competency-based education and related synonyms as discussed in [4]) refers to a pedagogical approach that supports the development of practical skills and behaviors that are necessary for success in real-world situations [5, 6]. A revised definition of competency-based learning distinguishes this concept into seven major aspects [6, 7]. Two of these aspects address the assessment of competencies: \"…(2) assessment is meaningful, timely, relevant, and actionable evidence; … (4) students’ assessment is based on evidence of mastery; [6, p.1904]\"(retrieved from Levine &amp; Patrick [7]).</p><p>\\\nFormative assessments are a major form of assessing competencies [8–11]. Usually, these kinds of assessments are typically incremental [9, 10, 12] and inform not only learners about their current state but also educators about the effectiveness of their pedagogical and didactical methods [11]. To design, develop, and implement formative assessments, various methodologies have been developed to derive these information for educators, for example, the ADDIE Model [13], Four – Component Instructional Design (4C/ID) [14] or the Evidence Centered-Design Framework (ECD) [15].</p><p>\\\nThe ECD is based on the idea that when learners fulfill tasks, they create some kind of result (work product) that incorporates, to some degree, the learner’s competence level [16]. Hence, extracting evidence from the work products within a defined evidence identification process leads to claims about certain competencies [15, 17, 18]. Collecting and storing these beliefs result in an individual description of each learner, a learner model. Thus, before constructing the actual assessment, it is necessary to reflect on all those stated parts and other aspects as well [15].</p><p>\\\nEducators usually act in a similar (but far less formal) way to develop and apply formative assessments in their educational settings, which costs them a lot of time. A recent McKinsey study ([19]) with a focus on K-12 teachers in the US, UK, CA, and SG reveals that they spend 34% of their time on preparation, evaluation, and feedback tasks [19, 20].</p><p>\\\nHence, researchers and developers have been eager to tailor computer-based learning experiences to the learner´s needs by using evidence about competencies to adapt the learning process autonomously [21– 23]. To achieve this, such systems incorporate learner models, task (or more general domain) models, and automated evidence identification processes and use those to generate adaption recommendations. Examples of conceptional formulations for such systems could be recommending the next best-fitting learning object (e.g., a task with a specific difficulty), finding a sequence of novel courses, or supporting the search for learning peers [24, 25].</p><p>\\\nNowadays, advanced systems are able to mimic the behaviors of human tutors by using artificial intelligence, which results in their classification as intelligent tutoring systems [26, 27]. To do so, these systems not only incorporate learner models and domain models but also so-called tutor models. The tutor model is the decision entity that schedules pedagogical or didactical interventions according to the state of the learner model as a response to the learner’s interaction [28]. As a result of this perspective, intelligent tutoring systems are designed and developed according to the meta-architectural approach illustrated by the gray elements in Figure 1 (see [26, 28–30]).</p>","contentLength":4840,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dual-Arm HyQReal Puts Powerful Telepresence Anywhere","url":"https://spectrum.ieee.org/telepresence-robot","date":1739289605,"author":"Evan Ackerman","guid":185,"unread":true,"content":"<p>IIT’s hydraulic quadruped can carry a pair of massive arms</p>","contentLength":60,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjE1MDg3MC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc2MzQyMjI5MH0.P7rZYSa6orpvLiwnLpf8wHNCw_oa4ckp2iPAj5ykgLg/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Before AI Predicts Your Next Friend, It Needs to Do This First","url":"https://hackernoon.com/before-ai-predicts-your-next-friend-it-needs-to-do-this-first?source=rss","date":1739289604,"author":"Andrei","guid":186,"unread":true,"content":"<p>In this post we'll continue working on link prediction with the Twitch dataset: we'll export the graph data from the Neptune DB cluster to an S3 bucket using the neptune-export utility provided by AWS. We'll choose the 'neptune_ml' profile when we create the data export task and the utility will create the 'training-data-configuration.json' file that we'll use later in the pipeline. The exported data will be ready for feature encoding and data processing, which is the next step required for link prediction.</p><p>We start with the graph data that we have in Neptune DB after uploading the lists of vertices and edges using the Neptune Bulk Loader API (as described in Part 1 of this guide).</p><p>\\\nThe vertices represent users. All vertices contain the same set of properties, and a single vertex looks like this:</p><pre><code>{&lt;T.id: 1&gt;: '153', &lt;T.label: 4&gt;: 'user', 'days': 1629, 'mature': True, 'views': 3615, 'partner': False}\n</code></pre><p>\\\nAll edges have the same label ('follows'), each edge connects 2 users. A single edge looks like this:</p><pre><code>{&lt;T.id: 1&gt;: '0', &lt;T.label: 4&gt;: 'follows', &lt;Direction.IN: 'IN'&gt;: {&lt;T.id: 1&gt;: '255', &lt;T.label: 4&gt;: 'user'}, &lt;Direction.OUT: 'OUT'&gt;: {&lt;T.id: 1&gt;: '6194', &lt;T.label: 4&gt;: 'user'}}\n</code></pre><p>\\\nOur goal is to export the data so that it can be used in the next part of our data pipeline: preprocessing and feature encoding.</p><h2>RUNNING THE NEPTUNE-EXPORT UTILITY ON EC2</h2><p>We'll use the  utility provided by AWS to export data from the database. To allow the utility access to the DB, we'll run it on an EC2 instance inside the VPC where the Neptune DB cluster is. The utility will get the data from the DB, save it in local storage (an EBS volume), and then it will upload the exported data to S3.</p><p>\\\nAlthough AWS provides a Cloudformation template that deploys a private API inside your VPC to allow the export process to be started with an HTTP request, we won't focus on that this time. As our goal is to demonstrate how the data pipeline works (and not to set up an API), we'll just use the EC2 instance's console to interact with the neptune-export utility. By the way, those console commands can be automated with AWS Systems Manager Run Command and Step Functions.</p><p>\\\nLet's create the EC2 instance that we'll run neptune-export on. For AMI, we choose Ubuntu 24.04 LTS. We need to make sure that the Neptune cluster is reachable from the EC2 instance, so we'll create the instance in the same VPC where the Neptune cluster is, and we'll configure the security groups to allow network traffic between the instance and the cluster. We also need to attach an EBS volume of sufficient size to contain the exported data. For the dataset that we're working on, an 8GB volume is enough.</p><p>\\\nWhile the instance is starting, we need to create an IAM role that allows write access to the destination S3 bucket, and also some RDS actions, as it is shown in the policy below. While the first statement of the policy is mandatory, the second one is only needed if you export data from a cloned cluster. Exporting data from cloned clusters will be be discussed later in this post.</p><pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"RequiredPart\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"rds:ListTagsForResource\",\n                \"rds:DescribeDBInstances\",\n                \"rds:DescribeDBClusters\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Sid\": \"OptionalPartOnlyRequiredForExportingFromClonedCluster\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"rds:AddTagsToResource\",\n                \"rds:DescribeDBClusters\",\n                \"rds:DescribeDBInstances\",\n                \"rds:ListTagsForResource\",\n                \"rds:DescribeDBClusterParameters\",\n                \"rds:DescribeDBParameters\",\n                \"rds:ModifyDBParameterGroup\",\n                \"rds:ModifyDBClusterParameterGroup\",\n                \"rds:RestoreDBClusterToPointInTime\",\n                \"rds:DeleteDBInstance\",\n                \"rds:DeleteDBClusterParameterGroup\",\n                \"rds:DeleteDBParameterGroup\",\n                \"rds:DeleteDBCluster\",\n                \"rds:CreateDBInstance\",\n                \"rds:CreateDBClusterParameterGroup\",\n                \"rds:CreateDBParameterGroup\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre><p>You can allow access to just the target cluster (instead of all clusters) by editing the ‘Resource’ field.</p><p>\\\nThe role must also have a trust policy that allows EC2 to assume the role:</p><pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"ec2.amazonaws.com\"\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n</code></pre><p>Once the EC2 instance and the role is ready, we'll attach the role to the instance.</p><p>\\\nNext, we need to install the neptune-export utility on the instance. To do that, we’ll log into the instance and use these commands to install JDK 8 and download the utility:</p><pre><code>sudo apt update -y\nsudo apt install -y openjdk-8-jdk\ncurl -O https://s3.amazonaws.com/aws-neptune-customer-samples/neptune-export/bin/neptune-export.jar\n</code></pre><p>Now that we've prepared the EC2 instance, the destination S3 bucket, and attached the IAM the role that allows write access to the destination S3 bucket to the instance, we can start exporting data. We'll use this command to initiate the process, providing the required parameters as a JSON object:</p><pre><code>java -jar /home/ubuntu/neptune-export.jar nesvc \\\n  --root-path /home/ubuntu/neptune-export \\\n  --json '{\n    \"command\": \"export-pg\",\n    \"outputS3Path\" : \"s3://YOUR_TARGET_S3_BUCKET/neptune-export\",\n    \"params\": {\n       \"endpoint\" : \"YOUR_CLUSTER_ENDPOINT\",\n       \"profile\": \"neptune_ml\"\n    }\n  }'\n</code></pre><p>We used only the required parameters here but you can easily extend the config. You can choose what part of the graph you export using the 'filter' parameter: you can select nodes, edges, and their properties.</p><p>\\\nIf you're exporting data from a live database, you can use the '' and '' parameters to make the neptue-export utility take a snapshot of the database, create a new Neptune cluster from that snapshot, deploy read replicas, and use them to export the data. By doing that, you can make sure the live database is not affected by the additional load from the data exporting.</p><h2>VIEWING EXPORTED DATA AND NEXT STEPS</h2><p>When the export process is completed, neptune-export prints some stats including the numbers of vertices and edges:</p><pre><code>Source:\n  Nodes: 7126\n  Edges: 70648\nExport:\n  Nodes: 7126\n  Edges: 70648\n  Properties: 28504\nDetails:\n  Nodes: \n    user: 7126\n        |_ days {propertyCount=7126, minCardinality=1, maxCardinality=1, recordCount=7126, dataTypeCounts=[Integer:7126]}\n        |_ mature {propertyCount=7126, minCardinality=1, maxCardinality=1, recordCount=7126, dataTypeCounts=[Boolean:7126]}\n        |_ views {propertyCount=7126, minCardinality=1, maxCardinality=1, recordCount=7126, dataTypeCounts=[Integer:7126]}\n        |_ partner {propertyCount=7126, minCardinality=1, maxCardinality=1, recordCount=7126, dataTypeCounts=[Boolean:7126]}\n  Edges: \n    (user)-follows-(user): 70648\n</code></pre><p>And then it uploads the exported data to S3.</p><p>\\\nLet's look at the files that are created in the target S3 bucket:</p><p>\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\nThe ‘nodes’ and ‘edges’ directories contain CSV files with the lists of nodes and edges that are similar to what we used in Part 1 when we uploaded data. For large graphs, there are multiple files, but our dataset is small and there's just one file in each directory. There's also the <strong>training-data-configuration.json</strong> file that we'll edit and use in the next step of our process.</p><p>\\\nIf you're doing a one time export, now it's safe to delete the EC2 instance and the EBS volume, since only the files in the target S3 bucket will be used in the next step. Otherwise, you can just stop the EC2 instance to avoid getting charged for idle time (you'll still be charged for EBS storage unless you delete it).</p><p>\\\n<strong>At this point we have the graph data in S3 in the format that can be used in the next step of the process, and we're ready to do feature encoding and data processing,</strong> which will be discussed in our next post.</p>","contentLength":8211,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"YouTube Surprise: CEO Says TV Overtakes Mobile as 'Primary Device' for Viewing","url":"https://news.slashdot.org/story/25/02/11/1541222/youtube-surprise-ceo-says-tv-overtakes-mobile-as-primary-device-for-viewing?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739288460,"author":"msmash","guid":283,"unread":true,"content":"If there was any doubt before, this seals it: YouTube is in the TV business. According to Neal Mohan, YouTube's CEO, TV screens have officially overtaken mobile as the \"primary device for YouTube viewing in the U.S.\" In other words, more people are watching YouTube on TV sets than any other device, at least here in the U.S. From a report: It is, as Mohan writes in his annual letter from the CEO, an indication that \"YouTube is the new television.\" \n\n\"But the 'new' television doesn't look like the 'old' television,\" Mohan writes. \"It's interactive and includes things like Shorts (yes, people watch them on TVs), podcasts, and live streams, right alongside the sports, sitcoms and talk shows people already love.\"","contentLength":717,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GNOME 48 Now Allows Grouping Notifications By App","url":"https://www.phoronix.com/news/GNOME-48-Notifications-App","date":1739287111,"author":"Michael Larabel","guid":712,"unread":true,"content":"<article>While the GNOME 48 feature and UI freezes went into effect just a little more than one week ago, a freeze exception was granted for merging support in GNOME Shell for grouping notifications on a per-app basis...</article>","contentLength":211,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ubuntu 25.04's GNOME Web Browser Will Be Able To Play More Web Videos By Default","url":"https://www.phoronix.com/news/Ubuntu-Epiphany-Bad-Plugins","date":1739285666,"author":"Michael Larabel","guid":711,"unread":true,"content":"<article>Those making use of the GNOME Web \"Epiphany\" web browser with the upcoming Ubuntu 25.04 release will be able to enjoy playing more popular web videos thanks to a packaging change...</article>","contentLength":181,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rubidium Can Be More Than a Lithium Cast-Off","url":"https://spectrum.ieee.org/rubidium","date":1739282404,"author":"Elissa Welle","guid":184,"unread":true,"content":"<p>New extraction techniques makes the element—essential in high-tech timekeeping—easier to mine</p>","contentLength":97,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjMyMTI2My9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc5MjI3MTA3OH0.Ryeo_Q5ykelatJkzIly879sUfQg0LtgR9rSWXhd5QV0/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Arm Mali Panfrost Driver Lands OpenCL C Support In Mesa 25.1","url":"https://www.phoronix.com/news/Panfrost-Lands-OpenCL-C","date":1739281560,"author":"Michael Larabel","guid":710,"unread":true,"content":"<article>The Panfrost Gallium3D driver has merged initial OpenCL C infrastructure into Mesa 25.1 for allowing OpenCL compute on Arm Mali graphics using this open-source Linux driver stack...</article>","contentLength":181,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FLAC 1.5 Finally Delivers Multi-Threaded Encoding","url":"https://www.phoronix.com/news/FLAC-1.5-Released","date":1739280999,"author":"Michael Larabel","guid":709,"unread":true,"content":"<article>FLAC 1.5 is out today as the newest feature update to the software built around the Free Lossless Audio Codec...</article>","contentLength":112,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rivian Flexes Software Power: What VW Gets for $5.7B","url":"https://spectrum.ieee.org/rivian-volkswagen-software-ev","date":1739278805,"author":"Lawrence Ulrich","guid":183,"unread":true,"content":"<p>Struggling to crack the code on EVs, VW bets big on Rivian</p>","contentLength":58,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjI2NDU4My9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc5OTA4MTY4OX0.wWq6j5o1EfjSUl0Y2ssr6wcIxkPln54qyXv3_YmvpXM/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"KDE Plasma 6.3 Released With Improved Fractional Scaling & Other Enhancements","url":"https://www.phoronix.com/news/KDE-Plasma-6.3-Released","date":1739274288,"author":"Michael Larabel","guid":708,"unread":true,"content":"<article>Out just ahead of Valentine's Day is the much anticipated KDE Plasma 6.3 desktop release for further advancing this Qt6/KF6-based open-source desktop...</article>","contentLength":152,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AMD AOMP 20.0-2 Compiler Adds The \"flang-new\" Fortran Compiler Option","url":"https://www.phoronix.com/news/AMD-AOMP-20.0-2","date":1739273062,"author":"Michael Larabel","guid":707,"unread":true,"content":"<article>AOMP 20.0-2 was released on Monday as the newest update to this AMD downstream of the LLVM/Clang/Flang code that is focused on delivering the latest staging/testing patches around OpenMP offloading to AMD GPUs using ROCm. Many of AMD's AMDGPU/OpenMP patches end up being upstreamed into LLVM proper while AOMP is the staging area for those wanting to have the latest and best experience for Clang C/C++ and Flang Fortran offloading to AMD Instinct/Radeon hardware...</article>","contentLength":466,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BeOS-Inspired Haiku OS Starts 2025 Off Introducing An AMD CPU Temperature Driver","url":"https://www.phoronix.com/news/Haiku-OS-2025-January","date":1739272387,"author":"Michael Larabel","guid":706,"unread":true,"content":"<article>The BeOS-inspired Haiku open-source operating system project has published their January 2025 status report that outlines all of the interesting work over the past month...</article>","contentLength":172,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Systemd Adding The Ability to Boot Directly Into A Disk Image Downloaded Via HTTP","url":"https://www.phoronix.com/news/systemd-disk-image-boot-HTTP","date":1739238189,"author":"Michael Larabel","guid":705,"unread":true,"content":"<article>Systemd lead developer Lennart Poettering has been working on adding the ability to let systemd boot directly into a disk image downloaded via HTTP within the initial RAM disk (initrd) during the Linux boot process...</article>","contentLength":217,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI’s secret weapon against Nvidia dependence takes shape","url":"https://arstechnica.com/ai/2025/02/openais-secret-weapon-against-nvidia-dependence-takes-shape/","date":1739221233,"author":"Benj Edwards","guid":358,"unread":true,"content":"<p>OpenAI is entering the final stages of designing its long-rumored AI processor with the aim of decreasing the company's dependence on Nvidia hardware, according to a <a href=\"https://www.reuters.com/technology/openai-set-finalize-first-custom-chip-design-this-year-2025-02-10/\">Reuters report</a> released Monday. The <a href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\">ChatGPT</a> creator plans to send its chip designs to Taiwan Semiconductor Manufacturing Co. (TSMC) for fabrication within the next few months, but the chip has not yet been formally announced.</p><p>The OpenAI chip's full capabilities, technical details, and exact timeline are still unknown, but the company reportedly intends to iterate on the design and improve it over time, giving it leverage in negotiations with chip suppliers—and potentially granting the company future independence with a chip design it controls outright.</p><p>In the past, we've seen other tech companies, such as <a href=\"https://arstechnica.com/information-technology/2023/11/microsoft-launches-custom-chips-to-accelerate-its-plans-for-ai-domination/\">Microsoft</a>, <a href=\"https://arstechnica.com/ai/2024/11/amazon-ready-to-use-its-own-ai-chips-reduce-its-dependence-on-nvidia/\">Amazon</a>, <a href=\"https://fortune.com/2024/04/09/google-building-ai-chips-axion-amin-vahdat-nvidia-h100-intel-gaudi-3/\">Google</a>, and <a href=\"https://www.reuters.com/technology/meta-debuts-new-generation-ai-chip-2024-04-10/\">Meta</a>, create their own AI acceleration chips for reasons that range from cost reduction to relieving shortages of AI chips supplied by Nvidia, which enjoys a <a href=\"https://arstechnica.com/tech-policy/2024/08/nvidias-dominance-puts-ai-industry-in-dire-danger-groups-warn-doj/\">near-market monopoly</a> on high-powered GPUs (such as the <a href=\"https://arstechnica.com/information-technology/2024/03/nvidia-unveils-blackwell-b200-the-worlds-most-powerful-chip-designed-for-ai/\">Blackwell series</a>) for data center use.</p>","contentLength":1061,"flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2025/02/ai_chip_illustration-1152x648.jpg","enclosureMime":"","commentsUrl":null},{"title":"Firefox ForkServer Getting Ready To Enhance Linux Browser Performance","url":"https://www.phoronix.com/news/Firefox-ForkServer-Linux-Nears","date":1739218289,"author":"Michael Larabel","guid":704,"unread":true,"content":"<article>Firefox has been shipping their nightly Linux builds the past three months with ForkServer enabled to improve the multi-process browser experience. The results are looking good and Firefox official releases for Linux should soon begin shipping with ForkServer too for this performance win...</article>","contentLength":291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Celebrating Steve Jobs’s Impact on Consumer Tech and Design","url":"https://spectrum.ieee.org/steve-jobs","date":1739214004,"author":"San Murugesan","guid":182,"unread":true,"content":"<p>A look back at his career on what would have been his 70th birthday</p>","contentLength":67,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjM3NzgxOC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc1NjIzMTg4N30.TjwFgXs9V-Zy7jC58zYwdVCPFYKyFxurZnzQNs9ICQM/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Gyroscope-on-a-Chip Targets GPS’s Dominance","url":"https://spectrum.ieee.org/optical-gyroscopes-on-chip","date":1739210404,"author":"Willie D. Jones","guid":181,"unread":true,"content":"<p>Centimeter-scale wayfinding accuracy emerges from millimeter-scale tech</p>","contentLength":71,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjEyMjY0MS9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc4MzM2MzQ3OX0.wBTG52F6192KrziO07XCyLR6oSBISZrkoUBwy5BH0n4/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Intel's Newest Open-Source Project Is \"Polite Guard\"","url":"https://www.phoronix.com/news/Intel-Polite-Guard","date":1739209200,"author":"Michael Larabel","guid":703,"unread":true,"content":"<article>Intel's newest open-source project and addition to their AI offerings is... Polite Guard...</article>","contentLength":91,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple Touch Bar Backlight & Keyboard Mode Drivers Slated For Linux 6.15","url":"https://www.phoronix.com/news/Apple-Touch-Bar-Linux-6.15","date":1739207902,"author":"Michael Larabel","guid":702,"unread":true,"content":"<article>For those making use of the Intel-powered Apple MacBook Pro laptops featuring the Touch Bar, better support for that interface is slated to land with the upcoming Linux 6.15 kernel cycle...</article>","contentLength":189,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GIMP 3.0 RC3 Released For A Final Round Of Testing","url":"https://www.phoronix.com/news/GIMP-3.0-RC3-Released","date":1739202660,"author":"Michael Larabel","guid":701,"unread":true,"content":"<article>GIMP 3.0 RC3 is out today as what is hopefully the last release candidate before the long-awaited stable release of GIMP 3.0 as this long in development free software alternative to the likes of Adobe Photoshop...</article>","contentLength":213,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python 3.14 Lands A New Interpreter With 3~30% Faster Python Code","url":"https://www.phoronix.com/news/Python-3.14-New-Interpreter","date":1739196150,"author":"Michael Larabel","guid":700,"unread":true,"content":"<article>Merged last week for Python 3.14 is a new tail-call intepreter that aims to offer significantly better performance with around 10% faster performance in PyPerformance or around a 40% speed-up in Python-heavy benchmarks. This tail-call interpeter can even outperform the current Python JIT compiler but for maximum performance benefits Python should be built with Profile Guided Optimizations (PGO)...</article>","contentLength":400,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"It’s Time To Rethink 6G","url":"https://spectrum.ieee.org/5g-bandwidth","date":1739196003,"author":"William Webb","guid":180,"unread":true,"content":"<p>It’s not more bandwidth that users need</p>","contentLength":41,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjEzMDA0MS9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc0NDEyMzk5Mn0.jPunQzFQ_dBRCyydxSdaI9lAn88q3l2GB9hsCIKa5BM/image.png?width=600","enclosureMime":"","commentsUrl":null},{"title":"Union Hopes To Address KDE's Fragmented Ways Of Styling Apps","url":"https://www.phoronix.com/news/KDE-Union-Hopes-Unified-Styling","date":1739195460,"author":"Michael Larabel","guid":699,"unread":true,"content":"<article>KDE/Qt apps can be styled many different ways with Qt widgets, SVG-based styling, Qt Quick, and other routes for styling of applications. That fragmentation of different ways to styling KDE apps can probe problematic for UI designs and lead to a less cohesive user experience. KDE developer Arjen Hiemstra is hoping to change that with the Union project...</article>","contentLength":356,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Formerly Known As YQPkg, Myrlyn Package Manager GUI Adds Repository Configuration","url":"https://www.phoronix.com/news/Myrlyn-Repo-Configuration","date":1739194106,"author":"Michael Larabel","guid":698,"unread":true,"content":"<article>You may recall the YQPkg package management tool announced last year that's been talked up by openSUSE developers as a Qt-based package manager GUI and alternative to YaST. It's now known as Myrlyn and has added repository configuration as its newest feature...</article>","contentLength":261,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Reveals Hidden Interior Design Rules of the Cell","url":"https://spectrum.ieee.org/ai-protein-localization","date":1739192404,"author":"Elie Dolgin","guid":179,"unread":true,"content":"<p>A new tool predicts where proteins fit, opening new frontiers in drug discovery</p>","contentLength":79,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjI2NzY5MC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc1NDA3NDYzOH0.X1yTNpRDu8eaQKN-SOF9IdMARfQ4nVEn7DAzQ4sE4D8/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"New Proposal To Raise The Linux Kernel's Default Timer Frequency To 1000Hz","url":"https://www.phoronix.com/news/Linux-2025-Proposal-1000Hz","date":1739187830,"author":"Michael Larabel","guid":697,"unread":true,"content":"<article>A patch sent out on Sunday by Google engineer Qais Yousef is proposing to raise the Linux kernel's default timer frequency from 250Hz to 1000Hz...</article>","contentLength":146,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RADV Vulkan Video Adds Low Latency Encoding Support","url":"https://www.phoronix.com/news/RADV-Vulkan-Video-Low-Latency","date":1739187102,"author":"Michael Larabel","guid":696,"unread":true,"content":"<article>Adding to the Vulkan Video support for Mesa's Radeon \"RADV\" Vulkan driver is honoring of the low latency encoding options...</article>","contentLength":124,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microsoft Continues Enhancing Its Azure Linux 3.0 Distribution With February Update","url":"https://www.phoronix.com/news/Azure-Linux-3.0.20250206","date":1739185640,"author":"Michael Larabel","guid":695,"unread":true,"content":"<article>Microsoft engineers released Azure Linux 3.0.20250206 overnight as the newest monthly update to this in-house Microsoft Linux distribution that is used within their Azure cloud infrastructure and a variety of other purposes at the Redmond company...</article>","contentLength":249,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["tech"]}